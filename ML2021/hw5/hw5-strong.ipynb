{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0-Ccn1_6LnW"
   },
   "source": [
    "# **Homework 5 - Sequence-to-sequence**\n",
    "\n",
    "若有任何問題，歡迎來信至助教信箱 ntu-ml-2021spring-ta@googlegroups.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEsCz4jW6Lnc"
   },
   "source": [
    "### (4/21 Updates)\n",
    "1. Link to reference [training curves](https://wandb.ai/george0828zhang/hw5.seq2seq.new).\n",
    "\n",
    "### (4/14 Updates) \n",
    "1. Link to tutorial [video](https://youtu.be/htG5WpZVQPU).\n",
    "2. Now defaults to load `\"avg_last_5_checkpoint.pt\"` to generate prediction.\n",
    "3. Expected run time on Colab with Tesla T4\n",
    "\n",
    "|Baseline|Details|Total Time|\n",
    "|-|:-:|:-:|\n",
    "|Simple|2m 15s $\\times$30 epochs|1hr 8m|\n",
    "|Medium|4m $\\times$30 epochs|2hr|\n",
    "|Strong|8m $\\times$30 epochs (backward)<br>+1hr (back-translation)<br>+15m $\\times$30 epochs (forward)|12hr 30m|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHRXrP-C6Lnc"
   },
   "source": [
    "# Sequence-to-Sequence 介紹\n",
    "- 大多數常見的 seq2seq model 為 encoder-decoder model，主要由兩個部分組成，分別是 encoder 和 decoder，而這兩個部可以使用 recurrent neural network (RNN)或 transformer 來實作，主要是用來解決輸入和輸出的長度不一樣的情況\n",
    "- **Encoder** 是將一連串的輸入，如文字、影片、聲音訊號等，編碼為單個向量，這單個向量可以想像為是整個輸入的抽象表示，包含了整個輸入的資訊\n",
    "- **Decoder** 是將 encoder 輸出的單個向量逐步解碼，一次輸出一個結果，直到將最後目標輸出被產生出來為止，每次輸出會影響下一次的輸出，一般會在開頭加入 \"< BOS >\" 來表示開始解碼，會在結尾輸出 \"< EOS >\" 來表示輸出結束\n",
    "\n",
    "\n",
    "![seq2seq](https://i.imgur.com/0zeDyuI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NhaOWfo6Lnd"
   },
   "source": [
    "# 作業介紹\n",
    "- 英文翻譯中文\n",
    "  - 輸入： 一句英文 （e.g.\t\ttom is a student .） \n",
    "  - 輸出： 中文翻譯 （e.g. \t\t湯姆 是 個 學生 。）\n",
    "\n",
    "- TODO\n",
    "  - 訓練一個 RNN 模型達到 Seq2seq 翻譯\n",
    "  - 訓練一個 Transformer 大幅提升效能\n",
    "  - 實作 Back-translation 大幅提升效能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7TvxMIx6Lnd"
   },
   "source": [
    "# 下載和引入需要的函式庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QapwZGa16Lnd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.6.0 in /home/bill/.local/lib/python3.8/site-packages (1.8.1+cu111)\n",
      "Requirement already satisfied: editdistance in /home/bill/.local/lib/python3.8/site-packages (0.5.3)\n",
      "Requirement already satisfied: matplotlib in /home/bill/.local/lib/python3.8/site-packages (3.3.4)\n",
      "Requirement already satisfied: sacrebleu in /home/bill/.local/lib/python3.8/site-packages (1.5.1)\n",
      "Requirement already satisfied: sacremoses in /home/bill/.local/lib/python3.8/site-packages (0.0.45)\n",
      "Requirement already satisfied: sentencepiece in /home/bill/.local/lib/python3.8/site-packages (0.1.95)\n",
      "Requirement already satisfied: tqdm in /home/bill/.local/lib/python3.8/site-packages (4.59.0)\n",
      "Requirement already satisfied: wandb in /home/bill/.local/lib/python3.8/site-packages (0.10.27)\n",
      "Requirement already satisfied: numpy in /home/bill/.local/lib/python3.8/site-packages (from torch>=1.6.0) (1.20.2)\n",
      "Requirement already satisfied: typing-extensions in /home/bill/.local/lib/python3.8/site-packages (from torch>=1.6.0) (3.7.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/bill/.local/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/bill/.local/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/bill/.local/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/bill/.local/lib/python3.8/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.7.3)\n",
      "Requirement already satisfied: portalocker==2.0.0 in /home/bill/.local/lib/python3.8/site-packages (from sacrebleu) (2.0.0)\n",
      "Requirement already satisfied: regex in /home/bill/.local/lib/python3.8/site-packages (from sacremoses) (2021.4.4)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from sacremoses) (7.0)\n",
      "Requirement already satisfied: joblib in /home/bill/.local/lib/python3.8/site-packages (from sacremoses) (1.0.1)\n",
      "Requirement already satisfied: six in /home/bill/.local/lib/python3.8/site-packages (from sacremoses) (1.15.0)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/bill/.local/lib/python3.8/site-packages (from wandb) (3.15.6)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/bill/.local/lib/python3.8/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/lib/python3/dist-packages (from wandb) (5.5.1)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /home/bill/.local/lib/python3.8/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: pathtools in /home/bill/.local/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/bill/.local/lib/python3.8/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /home/bill/.local/lib/python3.8/site-packages (from wandb) (1.0.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/bill/.local/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/lib/python3/dist-packages (from wandb) (2.22.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/bill/.local/lib/python3.8/site-packages (from wandb) (3.1.14)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /home/bill/.local/lib/python3.8/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: urllib3>=1.10.0 in /usr/lib/python3/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.25.8)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from sentry-sdk>=0.4.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/bill/.local/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /home/bill/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n",
      "Requirement already up-to-date: jupyter in /home/bill/.local/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already up-to-date: ipywidgets in /home/bill/.local/lib/python3.8/site-packages (7.6.3)\n",
      "Requirement already satisfied, skipping upgrade: notebook in /home/bill/.local/lib/python3.8/site-packages (from jupyter) (6.3.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-console in /home/bill/.local/lib/python3.8/site-packages (from jupyter) (6.4.0)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel in /home/bill/.local/lib/python3.8/site-packages (from jupyter) (5.5.3)\n",
      "Requirement already satisfied, skipping upgrade: qtconsole in /home/bill/.local/lib/python3.8/site-packages (from jupyter) (5.0.3)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in /home/bill/.local/lib/python3.8/site-packages (from jupyter) (6.0.7)\n",
      "Requirement already satisfied, skipping upgrade: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /home/bill/.local/lib/python3.8/site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.3.1 in /usr/lib/python3/dist-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=4.0.0; python_version >= \"3.3\" in /usr/lib/python3/dist-packages (from ipywidgets) (7.13.0)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /home/bill/.local/lib/python3.8/site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: nbformat>=4.2.0 in /home/bill/.local/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /home/bill/.local/lib/python3.8/site-packages (from notebook->jupyter) (0.10.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client>=5.3.4 in /home/bill/.local/lib/python3.8/site-packages (from notebook->jupyter) (6.1.12)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /home/bill/.local/lib/python3.8/site-packages (from notebook->jupyter) (2.11.3)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=6.1 in /home/bill/.local/lib/python3.8/site-packages (from notebook->jupyter) (6.1)\n",
      "Requirement already satisfied, skipping upgrade: argon2-cffi in /home/bill/.local/lib/python3.8/site-packages (from notebook->jupyter) (20.1.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.1 in /home/bill/.local/lib/python3.8/site-packages (from notebook->jupyter) (4.7.1)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=17 in /home/bill/.local/lib/python3.8/site-packages (from notebook->jupyter) (22.0.3)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/lib/python3/dist-packages (from notebook->jupyter) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.3 in /home/bill/.local/lib/python3.8/site-packages (from notebook->jupyter) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash>=1.5.0 in /home/bill/.local/lib/python3.8/site-packages (from notebook->jupyter) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/lib/python3/dist-packages (from jupyter-console->jupyter) (2.0.10)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /home/bill/.local/lib/python3.8/site-packages (from jupyter-console->jupyter) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: qtpy in /home/bill/.local/lib/python3.8/site-packages (from qtconsole->jupyter) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: jupyterlab-pygments in /home/bill/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /home/bill/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: nbclient<0.6.0,>=0.5.0 in /home/bill/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.3)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /usr/lib/python3/dist-packages (from nbconvert->jupyter) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /home/bill/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /home/bill/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /home/bill/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /home/bill/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (1.4.3)\n",
      "Requirement already satisfied, skipping upgrade: pexpect in /usr/lib/python3/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.6.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /home/bill/.local/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/lib/python3/dist-packages (from jupyter-client>=5.3.4->notebook->jupyter) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/lib/python3/dist-packages (from jinja2->notebook->jupyter) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.0.0 in /home/bill/.local/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (1.14.5)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/bill/.local/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess; os_name != \"nt\" in /home/bill/.local/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: nest-asyncio in /home/bill/.local/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: async-generator in /home/bill/.local/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter) (1.10)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /home/bill/.local/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (20.9)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /home/bill/.local/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /home/bill/.local/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.17.3)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/lib/python3/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (45.2.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /home/bill/.local/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (20.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /home/bill/.local/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.20)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /home/bill/.local/lib/python3.8/site-packages (from packaging->bleach->nbconvert->jupyter) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install 'torch>=1.6.0' editdistance matplotlib sacrebleu sacremoses sentencepiece tqdm wandb\n",
    "!pip3 install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8SOEQYjG6Lne"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'fairseq' already exists and is not an empty directory.\n",
      "HEAD is now at 9a1c4970 Make Hydra logging work with DDP (#1568)\n",
      "Processing ./fairseq\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: regex in /home/bill/.local/lib/python3.8/site-packages (from fairseq==1.0.0a0+9a1c497) (2021.4.4)\n",
      "Requirement already satisfied, skipping upgrade: omegaconf<2.1 in /home/bill/.local/lib/python3.8/site-packages (from fairseq==1.0.0a0+9a1c497) (2.0.6)\n",
      "Requirement already satisfied, skipping upgrade: cffi in /home/bill/.local/lib/python3.8/site-packages (from fairseq==1.0.0a0+9a1c497) (1.14.5)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /home/bill/.local/lib/python3.8/site-packages (from fairseq==1.0.0a0+9a1c497) (4.59.0)\n",
      "Requirement already satisfied, skipping upgrade: hydra-core<1.1 in /home/bill/.local/lib/python3.8/site-packages (from fairseq==1.0.0a0+9a1c497) (1.0.6)\n",
      "Requirement already satisfied, skipping upgrade: numpy; python_version >= \"3.7\" in /home/bill/.local/lib/python3.8/site-packages (from fairseq==1.0.0a0+9a1c497) (1.20.2)\n",
      "Requirement already satisfied, skipping upgrade: cython in /home/bill/.local/lib/python3.8/site-packages (from fairseq==1.0.0a0+9a1c497) (0.29.23)\n",
      "Requirement already satisfied, skipping upgrade: sacrebleu>=1.4.12 in /home/bill/.local/lib/python3.8/site-packages (from fairseq==1.0.0a0+9a1c497) (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: torch in /home/bill/.local/lib/python3.8/site-packages (from fairseq==1.0.0a0+9a1c497) (1.8.1+cu111)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /home/bill/.local/lib/python3.8/site-packages (from omegaconf<2.1->fairseq==1.0.0a0+9a1c497) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML>=5.1.* in /usr/lib/python3/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+9a1c497) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /home/bill/.local/lib/python3.8/site-packages (from cffi->fairseq==1.0.0a0+9a1c497) (2.20)\n",
      "Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.9\" in /home/bill/.local/lib/python3.8/site-packages (from hydra-core<1.1->fairseq==1.0.0a0+9a1c497) (5.1.2)\n",
      "Requirement already satisfied, skipping upgrade: antlr4-python3-runtime==4.8 in /home/bill/.local/lib/python3.8/site-packages (from hydra-core<1.1->fairseq==1.0.0a0+9a1c497) (4.8)\n",
      "Requirement already satisfied, skipping upgrade: portalocker==2.0.0 in /home/bill/.local/lib/python3.8/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+9a1c497) (2.0.0)\n",
      "Building wheels for collected packages: fairseq\n",
      "  Building wheel for fairseq (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-1.0.0a0+9a1c497-cp38-cp38-linux_x86_64.whl size=2120953 sha256=3939fe33922069a2243b051b1b9c3da7a76d801436296cfe84d2db2b24cbb898\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-v26a8j1f/wheels/21/d8/8f/e803e4e59232f7570ad689490b5a241021ce2800706905d1e5\n",
      "Successfully built fairseq\n",
      "Installing collected packages: fairseq\n",
      "  Attempting uninstall: fairseq\n",
      "    Found existing installation: fairseq 1.0.0a0+9a1c497\n",
      "    Uninstalling fairseq-1.0.0a0+9a1c497:\n",
      "      Successfully uninstalled fairseq-1.0.0a0+9a1c497\n",
      "Successfully installed fairseq-1.0.0a0+9a1c497\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pytorch/fairseq.git\n",
    "!cd fairseq && git checkout 9a1c497\n",
    "!pip3 install --upgrade ./fairseq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sFTuHtXS6Lne"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pdb\n",
    "import pprint\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "from fairseq import utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iF3PwwBb6Lne"
   },
   "source": [
    "# 設定種子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F6RjxoYo6Lnf"
   },
   "outputs": [],
   "source": [
    "seed = 73\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "np.random.seed(seed)  \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liDJlHFy6Lnf"
   },
   "source": [
    "# 資料集介紹\n",
    "\n",
    "## 英轉繁雙語資料\n",
    "* [TED2020](#reimers-2020-multilingual-sentence-bert)\n",
    "    - 原始資料量: 398,066句    \n",
    "    - 處理後資料: 393,980句\n",
    "    \n",
    "\n",
    "## 測試資料\n",
    "- 資料量: 4,000句\n",
    "- **中文部分不公開，提供的檔案為假翻譯，全部都是句點。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDA0va9x6Lnf"
   },
   "source": [
    "# 資料下載"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4js2tkA6Lnf"
   },
   "source": [
    "### 安裝megatools (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HK8chOJ-6Lnf"
   },
   "outputs": [],
   "source": [
    "#!apt-get install megatools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34Jj6KHC6Lnf"
   },
   "source": [
    "## 下載檔案並解壓縮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dKjeXrHK6Lng"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw.en\n",
      "raw.zh\n",
      "test.en\n",
      "test.zh\n"
     ]
    }
   ],
   "source": [
    "data_dir = './DATA/rawdata'\n",
    "dataset_name = 'ted2020'\n",
    "urls = (\n",
    "    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214989&authkey=AGgQ-DaR8eFSl1A\"', \n",
    "    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214987&authkey=AA4qP_azsicwZZM\"',\n",
    "# # If the above links die, use the following instead. \n",
    "#     \"https://www.csie.ntu.edu.tw/~r09922057/ML2021-hw5/ted2020.tgz\",\n",
    "#     \"https://www.csie.ntu.edu.tw/~r09922057/ML2021-hw5/test.tgz\",\n",
    "# # If the above links die, use the following instead. \n",
    "#     \"https://mega.nz/#!vEcTCISJ!3Rw0eHTZWPpdHBTbQEqBDikDEdFPr7fI8WxaXK9yZ9U\",\n",
    "#     \"https://mega.nz/#!zNcnGIoJ!oPJX9AvVVs11jc0SaK6vxP_lFUNTkEcK2WbxJpvjU5Y\",\n",
    ")\n",
    "file_names = (\n",
    "    'ted2020.tgz', # train & dev\n",
    "    'test.tgz', # test\n",
    ")\n",
    "prefix = Path(data_dir).absolute() / dataset_name\n",
    "\n",
    "prefix.mkdir(parents=True, exist_ok=True)\n",
    "for u, f in zip(urls, file_names):\n",
    "    path = prefix/f\n",
    "    if not path.exists():\n",
    "        if 'mega' in u:\n",
    "            !megadl {u} --path {path}\n",
    "        else:\n",
    "            !wget {u} -O {path}\n",
    "    if path.suffix == \".tgz\":\n",
    "        !tar -xvf {path} -C {prefix}\n",
    "    elif path.suffix == \".zip\":\n",
    "        !unzip -o {path} -d {prefix}\n",
    "!mv {prefix/'raw.en'} {prefix/'train_dev.raw.en'}\n",
    "!mv {prefix/'raw.zh'} {prefix/'train_dev.raw.zh'}\n",
    "!mv {prefix/'test.en'} {prefix/'test.raw.en'}\n",
    "!mv {prefix/'test.zh'} {prefix/'test.raw.zh'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZ8L-hSI6Lng"
   },
   "source": [
    "## 設定語言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "shrPIjki6Lng"
   },
   "outputs": [],
   "source": [
    "src_lang = 'zh'\n",
    "tgt_lang = 'en'\n",
    "\n",
    "data_prefix = f'{prefix}/train_dev.raw'\n",
    "test_prefix = f'{prefix}/test.raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OFjRsRjj6Lng"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非常謝謝你，克里斯。能有這個機會第二度踏上這個演講台\n",
      "真是一大榮幸。我非常感激。\n",
      "這個研討會給我留下了極為深刻的印象，我想感謝大家 對我之前演講的好評。\n",
      "我是由衷的想這麼說，有部份原因是因為 —— 我真的有需要!\n",
      "請你們設身處地為我想一想！\n",
      "Thank you so much, Chris.\n",
      "And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\n",
      "I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.\n",
      "And I say that sincerely, partly because  I need that.\n",
      "Put yourselves in my position.\n"
     ]
    }
   ],
   "source": [
    "!head {data_prefix+'.'+src_lang} -n 5\n",
    "!head {data_prefix+'.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aB-gbgAp6Lnh"
   },
   "source": [
    "## 檔案前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WUvmA4qI6Lnh"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def strQ2B(ustring):\n",
    "    \"\"\"把字串全形轉半形\"\"\"\n",
    "    # 參考來源:https://ithelp.ithome.com.tw/articles/10233122\n",
    "    ss = []\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # 全形空格直接轉換\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全形字元（除空格）根據關係轉化\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss.append(rstring)\n",
    "    return ''.join(ss)\n",
    "                \n",
    "def clean_s(s, lang):\n",
    "    if lang == 'en':\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "        s = s.replace('-', '') # remove '-'\n",
    "        s = re.sub('([.,;!?()\\\"])', r' \\1 ', s) # keep punctuation\n",
    "    elif lang == 'zh':\n",
    "        s = strQ2B(s) # Q2B\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "        s = s.replace(' ', '')\n",
    "        s = s.replace('—', '')\n",
    "        s = s.replace('“', '\"')\n",
    "        s = s.replace('”', '\"')\n",
    "        s = s.replace('_', '')\n",
    "        s = re.sub('([。,;!?()\\\"~「」])', r' \\1 ', s) # keep punctuation\n",
    "    s = ' '.join(s.strip().split())\n",
    "    return s\n",
    "\n",
    "def len_s(s, lang):\n",
    "    if lang == 'zh':\n",
    "        return len(s)\n",
    "    return len(s.split())\n",
    "\n",
    "def clean_corpus(prefix, l1, l2, ratio=9, max_len=1000, min_len=1):\n",
    "    if Path(f'{prefix}.clean.{l1}').exists() and Path(f'{prefix}.clean.{l2}').exists():\n",
    "        print(f'{prefix}.clean.{l1} & {l2} exists. skipping clean.')\n",
    "        return\n",
    "    with open(f'{prefix}.{l1}', 'r') as l1_in_f:\n",
    "        with open(f'{prefix}.{l2}', 'r') as l2_in_f:\n",
    "            with open(f'{prefix}.clean.{l1}', 'w') as l1_out_f:\n",
    "                with open(f'{prefix}.clean.{l2}', 'w') as l2_out_f:\n",
    "                    for s1 in l1_in_f:\n",
    "                        s1 = s1.strip()\n",
    "                        s2 = l2_in_f.readline().strip()\n",
    "                        s1 = clean_s(s1, l1)\n",
    "                        s2 = clean_s(s2, l2)\n",
    "                        s1_len = len_s(s1, l1)\n",
    "                        s2_len = len_s(s2, l2)\n",
    "                        if min_len > 0: # remove short sentence\n",
    "                            if s1_len < min_len or s2_len < min_len:\n",
    "                                continue\n",
    "                        if max_len > 0: # remove long sentence\n",
    "                            if s1_len > max_len or s2_len > max_len:\n",
    "                                continue\n",
    "                        if ratio > 0: # remove by ratio of length\n",
    "                            if s1_len/s2_len > ratio or s2_len/s1_len > ratio:\n",
    "                                continue\n",
    "                        print(s1, file=l1_out_f)\n",
    "                        print(s2, file=l2_out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zthe_GYM6Lnh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/ted2020/train_dev.raw.clean.zh & en exists. skipping clean.\n",
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/ted2020/test.raw.clean.zh & en exists. skipping clean.\n"
     ]
    }
   ],
   "source": [
    "clean_corpus(data_prefix, src_lang, tgt_lang)\n",
    "clean_corpus(test_prefix, src_lang, tgt_lang, ratio=-1, min_len=-1, max_len=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ayZ3FIcC6Lni"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非常謝謝你 , 克里斯 。 能有這個機會第二度踏上這個演講台\n",
      "真是一大榮幸 。 我非常感激 。\n",
      "這個研討會給我留下了極為深刻的印象 , 我想感謝大家對我之前演講的好評 。\n",
      "我是由衷的想這麼說 , 有部份原因是因為我真的有需要 !\n",
      "請你們設身處地為我想一想 !\n",
      "Thank you so much , Chris .\n",
      "And it's truly a great honor to have the opportunity to come to this stage twice ; I'm extremely grateful .\n",
      "I have been blown away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n",
      "And I say that sincerely , partly because I need that .\n",
      "Put yourselves in my position .\n"
     ]
    }
   ],
   "source": [
    "!head {data_prefix+'.clean.'+src_lang} -n 5\n",
    "!head {data_prefix+'.clean.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JorOC4O6Lni"
   },
   "source": [
    "## 切出 train/valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fgIncCB_6Lni"
   },
   "outputs": [],
   "source": [
    "valid_ratio = 0.01 # 3000~4000句就夠了\n",
    "train_ratio = 1 - valid_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LwTgbWeM6Lni"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/valid splits exists. skipping split.\n"
     ]
    }
   ],
   "source": [
    "if (prefix/f'train.clean.{src_lang}').exists() \\\n",
    "and (prefix/f'train.clean.{tgt_lang}').exists() \\\n",
    "and (prefix/f'valid.clean.{src_lang}').exists() \\\n",
    "and (prefix/f'valid.clean.{tgt_lang}').exists():\n",
    "    print(f'train/valid splits exists. skipping split.')\n",
    "else:\n",
    "    line_num = sum(1 for line in open(f'{data_prefix}.clean.{src_lang}'))\n",
    "    labels = list(range(line_num))\n",
    "    random.shuffle(labels)\n",
    "    for lang in [src_lang, tgt_lang]:\n",
    "        train_f = open(os.path.join(data_dir, dataset_name, f'train.clean.{lang}'), 'w')\n",
    "        valid_f = open(os.path.join(data_dir, dataset_name, f'valid.clean.{lang}'), 'w')\n",
    "        count = 0\n",
    "        for line in open(f'{data_prefix}.clean.{lang}', 'r'):\n",
    "            if labels[count]/line_num < train_ratio:\n",
    "                train_f.write(line)\n",
    "            else:\n",
    "                valid_f.write(line)\n",
    "            count += 1\n",
    "        train_f.close()\n",
    "        valid_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79D8y3gy6Lnj"
   },
   "source": [
    "## Subword Units \n",
    "翻譯存在的一大問題是未登錄詞(out of vocabulary)，可以使用 subword units 作為斷詞單位來解決。\n",
    "- 使用 [sentencepiece](#kudo-richardson-2018-sentencepiece) 套件\n",
    "- 用 unigram 或 byte-pair encoding (BPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "R1oiD8i46Lnj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/ted2020/spm8000.model exists. skipping spm_train.\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "vocab_size = 8000\n",
    "if (prefix/f'spm{vocab_size}.model').exists():\n",
    "    print(f'{prefix}/spm{vocab_size}.model exists. skipping spm_train.')\n",
    "else:\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=','.join([f'{prefix}/train.clean.{src_lang}',\n",
    "                        f'{prefix}/valid.clean.{src_lang}',\n",
    "                        f'{prefix}/train.clean.{tgt_lang}',\n",
    "                        f'{prefix}/valid.clean.{tgt_lang}']),\n",
    "        model_prefix=prefix/f'spm{vocab_size}',\n",
    "        vocab_size=vocab_size,\n",
    "        character_coverage=1,\n",
    "        model_type='unigram', # 'bpe' 也可\n",
    "        input_sentence_size=1e6,\n",
    "        shuffle_input_sentence=True,\n",
    "        normalization_rule_name='nmt_nfkc_cf',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "m-6ZfzBI6Lnj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/ted2020/train.zh exists. skipping spm_encode.\n",
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/ted2020/train.en exists. skipping spm_encode.\n",
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/ted2020/valid.zh exists. skipping spm_encode.\n",
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/ted2020/valid.en exists. skipping spm_encode.\n"
     ]
    }
   ],
   "source": [
    "spm_model = spm.SentencePieceProcessor(model_file=str(prefix/f'spm{vocab_size}.model'))\n",
    "in_tag = {\n",
    "    'train': 'train.clean',\n",
    "    'valid': 'valid.clean',\n",
    "    'test': 'test.raw.clean',\n",
    "}\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    for lang in [src_lang, tgt_lang]:\n",
    "        out_path = prefix/f'{split}.{lang}'\n",
    "        if out_path.exists():\n",
    "            print(f\"{out_path} exists. skipping spm_encode.\")\n",
    "        else:\n",
    "            with open(prefix/f'{split}.{lang}', 'w') as out_f:\n",
    "                with open(prefix/f'{in_tag[split]}.{lang}', 'r') as in_f:\n",
    "                    for line in in_f:\n",
    "                        line = line.strip()\n",
    "                        tok = spm_model.encode(line, out_type=str)\n",
    "                        print(' '.join(tok), file=out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "k8p5r8kc6Lnj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁ 非常 謝 謝 你 ▁, ▁ 克 里 斯 ▁ 。 ▁ 能 有 這個 機會 第二 度 踏 上 這個 演講 台\n",
      "▁ 真 是 一 大 榮 幸 ▁ 。 ▁我 非常 感 激 ▁ 。\n",
      "▁這個 研 討 會 給我 留 下 了 極 為 深 刻 的 印 象 ▁, ▁我想 感 謝 大家 對 我 之前 演講 的 好 評 ▁ 。\n",
      "▁我 是由 衷 的 想 這麼 說 ▁, ▁有 部份 原因 是因為 我 真的 有 需要 ▁ !\n",
      "▁ 請 你們 設 身 處 地 為 我想 一 想 ▁ !\n",
      "▁thank ▁you ▁so ▁much ▁, ▁chris ▁.\n",
      "▁and ▁it ' s ▁ t ru ly ▁a ▁great ▁ho n or ▁to ▁have ▁the ▁ op port un ity ▁to ▁come ▁to ▁this ▁st age ▁ t wi ce ▁ ; ▁i ' m ▁ex t re me ly ▁gr ate ful ▁.\n",
      "▁i ▁have ▁been ▁ bl own ▁away ▁by ▁this ▁con fer ence ▁, ▁and ▁i ▁want ▁to ▁thank ▁all ▁of ▁you ▁for ▁the ▁many ▁ ni ce ▁ com ment s ▁about ▁what ▁i ▁had ▁to ▁say ▁the ▁other ▁night ▁.\n",
      "▁and ▁i ▁say ▁that ▁since re ly ▁, ▁part ly ▁because ▁i ▁need ▁that ▁.\n",
      "▁put ▁your s el ve s ▁in ▁my ▁po s ition ▁.\n"
     ]
    }
   ],
   "source": [
    "!head {data_dir+'/'+dataset_name+'/train.'+src_lang} -n 5\n",
    "!head {data_dir+'/'+dataset_name+'/train.'+tgt_lang} -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alLs_5-R6Lnj"
   },
   "source": [
    "## 用 fairseq 將資料轉為 binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "o70IyuVH6Lnk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA/data-bin/ted2020 exists, will not overwrite!\n"
     ]
    }
   ],
   "source": [
    "binpath = Path('./DATA/data-bin', dataset_name)\n",
    "if binpath.exists():\n",
    "    print(binpath, \"exists, will not overwrite!\")\n",
    "else:\n",
    "    !python3 -m fairseq_cli.preprocess \\\n",
    "        --source-lang {src_lang}\\\n",
    "        --target-lang {tgt_lang}\\\n",
    "        --trainpref {prefix/'train'}\\\n",
    "        --validpref {prefix/'valid'}\\\n",
    "        --testpref {prefix/'test'}\\\n",
    "        --destdir {binpath}\\\n",
    "        --joined-dictionary\\\n",
    "        --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSBmUphm6Lnk"
   },
   "source": [
    "# 實驗的參數設定表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xhnisT4J6Lnk"
   },
   "outputs": [],
   "source": [
    "config = Namespace(\n",
    "    datadir = \"./DATA/data-bin/ted2020\",\n",
    "    savedir = \"./checkpoints/rnn\",\n",
    "    source_lang = \"zh\",\n",
    "    target_lang = \"en\",\n",
    "    \n",
    "    # cpu threads when fetching & processing data.\n",
    "    num_workers=1,  \n",
    "    # batch size in terms of tokens. gradient accumulation increases the effective batchsize.\n",
    "    max_tokens=4096,\n",
    "    accum_steps=4,\n",
    "    \n",
    "    # the lr s calculated from Noam lr scheduler. you can tune the maximum lr by this factor.\n",
    "    lr_factor=2.,\n",
    "    lr_warmup=4000,\n",
    "    \n",
    "    # clipping gradient norm helps alleviate gradient exploding\n",
    "    clip_norm=1.0,\n",
    "    \n",
    "    # maximum epochs for training\n",
    "    max_epoch=30,\n",
    "    start_epoch=1,\n",
    "    \n",
    "    # beam size for beam search\n",
    "    beam=10, \n",
    "    # generate sequences of maximum length ax + b, where x is the source length\n",
    "    max_len_a=1.2, \n",
    "    max_len_b=10,\n",
    "    # when decoding, post process sentence by removing sentencepiece symbols.\n",
    "    post_process = \"sentencepiece\",\n",
    "    \n",
    "    # checkpoints\n",
    "    keep_last_epochs=5,\n",
    "    resume=None, # if resume from checkpoint name (under config.savedir)\n",
    "    \n",
    "    # logging\n",
    "    use_wandb=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9h2l2Nv6Lnk"
   },
   "source": [
    "# Logging\n",
    "- logging 套件紀錄一般訊息\n",
    "- wandb 紀錄續練過程 loss, bleu, model weight 等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Te97W8IO6Lnk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=\"INFO\", # \"DEBUG\" \"WARNING\" \"ERROR\"\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "proj = \"hw5.seq2seq\"\n",
    "logger = logging.getLogger(proj)\n",
    "if config.use_wandb:\n",
    "    import wandb\n",
    "    wandb.init(project=proj, name=Path(config.savedir).stem, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5EggtU46Lnk"
   },
   "source": [
    "# CUDA環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "i-v6gPsh6Lnl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:44:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2021-04-29 15:44:36 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.758 GB ; name = GeForce RTX 2080 Ti                     \n",
      "2021-04-29 15:44:36 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n"
     ]
    }
   ],
   "source": [
    "cuda_env = utils.CudaEnvironment()\n",
    "utils.CudaEnvironment.pretty_print_cuda_env_list([cuda_env])\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-A0hYn1l6Lnl"
   },
   "source": [
    "# 讀取資料集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHJShm1h6Lnl"
   },
   "source": [
    "## 借用 fairseq 的 TranslationTask\n",
    "* 用來讀進上面 binarized 的檔案\n",
    "* 有現成的 data iterator (dataloader)\n",
    "* 字典 task.source_dictionary 和 task.target_dictionary 也很好用 \n",
    "* 有實做 beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "HgbvbrIM6Lnl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:44:36 | INFO | fairseq.tasks.translation | [zh] dictionary: 8000 types\n",
      "2021-04-29 15:44:36 | INFO | fairseq.tasks.translation | [en] dictionary: 8000 types\n"
     ]
    }
   ],
   "source": [
    "from fairseq.tasks.translation import TranslationConfig, TranslationTask\n",
    "\n",
    "## setup task\n",
    "task_cfg = TranslationConfig(\n",
    "    data=config.datadir,\n",
    "    source_lang=config.source_lang,\n",
    "    target_lang=config.target_lang,\n",
    "    train_subset=\"train\",\n",
    "    required_seq_len_multiple=8,\n",
    "    dataset_impl=\"mmap\",\n",
    "    upsample_primary=1,\n",
    ")\n",
    "task = TranslationTask.setup_task(task_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dLy3Lomf6Lnl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:44:36 | INFO | hw5.seq2seq | loading data for epoch 1\n",
      "2021-04-29 15:44:36 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020/train.zh-en.zh\n",
      "2021-04-29 15:44:36 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020/train.zh-en.en\n",
      "2021-04-29 15:44:36 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 train zh-en 390041 examples\n",
      "2021-04-29 15:44:36 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020/valid.zh-en.zh\n",
      "2021-04-29 15:44:36 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020/valid.zh-en.en\n",
      "2021-04-29 15:44:36 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 valid zh-en 3939 examples\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"loading data for epoch 1\")\n",
    "task.load_dataset(split=\"train\", epoch=1, combine=True) # combine if you have back-translation data.\n",
    "task.load_dataset(split=\"valid\", epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "bfJaV8Qp6Lnl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1,\n",
      " 'source': tensor([ 145,  684,   30,  270,   40,  168, 1134,  650,  591,  367, 3117, 2417,\n",
      "        1420,  194,    2]),\n",
      " 'target': tensor([  18,   14,    6, 2218,   60,   19,   75,    4,  253,   16,  334, 1392,\n",
      "        1689,    7,    2])}\n",
      "'Source: 這實在就是我所做的--光學操控思想'\n",
      "\"Target: that's exactly what i do optical mind control .\"\n"
     ]
    }
   ],
   "source": [
    "sample = task.dataset(\"valid\")[1]\n",
    "pprint.pprint(sample)\n",
    "pprint.pprint(\n",
    "    \"Source: \" + \\\n",
    "    task.source_dictionary.string(\n",
    "        sample['source'],\n",
    "        config.post_process,\n",
    "    )\n",
    ")\n",
    "pprint.pprint(\n",
    "    \"Target: \" + \\\n",
    "    task.target_dictionary.string(\n",
    "        sample['target'],\n",
    "        config.post_process,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfLLt7rX6Lnl"
   },
   "source": [
    "## Dataset Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vjm9sPD96Lnl"
   },
   "source": [
    "* 將每個 batch 控制在 N 個 token 讓 GPU 記憶體更有效被利用\n",
    "* 讓 training set 每個 epoch 有不同 shuffling\n",
    "* 濾掉長度太長的句子\n",
    "* 將每個 batch 內的句子 pad 成一樣長，好讓 GPU 平行運算\n",
    "* 加上 eos 並 shift 一格\n",
    "    - teacher forcing: 為了訓練模型根據prefix生成下個字，decoder的輸入會是輸出目標序列往右shift一格。\n",
    "    - 一般是會在輸入開頭加個bos token (如下圖)\n",
    "![seq2seq](https://i.imgur.com/0zeDyuI.png)\n",
    "    - fairseq 則是直接把 eos 挪到 beginning，訓練起來效果其實差不多。例如: \n",
    "    ```\n",
    "    # 輸出目標 (target) 和 Decoder輸入 (prev_output_tokens): \n",
    "                   eos = 2\n",
    "                target = 419,  711,  238,  888,  792,   60,  968,    8,    2\n",
    "    prev_output_tokens = 2,  419,  711,  238,  888,  792,   60,  968,    8\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OtxjBWjQ6Lnm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:44:36 | WARNING | fairseq.tasks.fairseq_task | 2,586 samples have invalid sizes and will be skipped, max_positions=(20, 20), first few sample ids=[3525, 1062, 527, 2861, 2415, 1633, 1624, 2626, 210, 880]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': tensor([3517]),\n",
       " 'nsentences': 1,\n",
       " 'ntokens': 17,\n",
       " 'net_input': {'src_tokens': tensor([[   1,    1,    1,    4, 1259, 2926,  157, 3552, 1591,  137,  162, 1173,\n",
       "            434,    4,   33,    2]]),\n",
       "  'src_lengths': tensor([13]),\n",
       "  'prev_output_tokens': tensor([[   2,    4,   32,   63,    8,  796, 1556, 1562,   13,  691,  116,  124,\n",
       "            188,    4,   33,    4,   32,    1,    1,    1,    1,    1,    1,    1]])},\n",
       " 'target': tensor([[   4,   32,   63,    8,  796, 1556, 1562,   13,  691,  116,  124,  188,\n",
       "             4,   33,    4,   32,    2,    1,    1,    1,    1,    1,    1,    1]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_iterator(task, split, epoch=1, max_tokens=4000, num_workers=1, cached=True):\n",
    "    batch_iterator = task.get_batch_iterator(\n",
    "        dataset=task.dataset(split),\n",
    "        max_tokens=max_tokens,\n",
    "        max_sentences=None,\n",
    "        max_positions=utils.resolve_max_positions(\n",
    "            task.max_positions(),\n",
    "            max_tokens,\n",
    "        ),\n",
    "        ignore_invalid_inputs=True,\n",
    "        seed=seed,\n",
    "        num_workers=num_workers,\n",
    "        epoch=epoch,\n",
    "        disable_iterator_cache=not cached,\n",
    "        # Set this to False to speed up. However, if set to False, changing max_tokens beyond \n",
    "        # first call of this method has no effect. \n",
    "    )\n",
    "    return batch_iterator\n",
    "\n",
    "demo_epoch_obj = load_data_iterator(task, \"valid\", epoch=1, max_tokens=20, num_workers=1, cached=False)\n",
    "demo_iter = demo_epoch_obj.next_epoch_itr(shuffle=True)\n",
    "sample = next(demo_iter)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.2'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.version.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDQ_rP6R6Lnm"
   },
   "source": [
    "* 每個 batch 是一個字典，key 是字串，value 是 Tensor，內容說明如下\n",
    "```python\n",
    "batch = {\n",
    "    \"id\": id, # 每個 example 的 id\n",
    "    \"nsentences\": len(samples), # batch size 句子數\n",
    "    \"ntokens\": ntokens, # batch size 字數\n",
    "    \"net_input\": {\n",
    "        \"src_tokens\": src_tokens, # 來源語言的序列\n",
    "        \"src_lengths\": src_lengths, # 每句話沒有 pad 過的長度\n",
    "        \"prev_output_tokens\": prev_output_tokens, # 上面提到右 shift 一格後的目標序列\n",
    "    },\n",
    "    \"target\": target, # 目標序列\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvKRIKsk6Lnm"
   },
   "source": [
    "# 定義模型架構\n",
    "* 我們一樣繼承 fairseq 的 encoder, decoder 和 model, 這樣測試階段才能直接用他寫好的 beam search 函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NuywtnWj6Lnm"
   },
   "outputs": [],
   "source": [
    "from fairseq.models import (\n",
    "    FairseqEncoder, \n",
    "    FairseqIncrementalDecoder,\n",
    "    FairseqEncoderDecoderModel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnFZGpT-6Lnm"
   },
   "source": [
    "## Encoder 編碼器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX5r3_MX6Lnm"
   },
   "source": [
    "- seq2seq 模型的編碼器為 RNN 或 Transformer Encoder，以下說明以 RNN 為例，Transformer 略有不同。對於每個輸入，Encoder 會輸出一個向量和一個隱藏狀態(hidden state)，並將隱藏狀態用於下一個輸入。換句話說，Encoder 會逐步讀取輸入序列，並在每個 timestep 輸出單個向量，以及在最後 timestep 輸出最終隱藏狀態(content vector)\n",
    "- 參數:\n",
    "  - *args*\n",
    "      - encoder_embed_dim 是 embedding 的維度，主要將 one-hot vector 的單詞向量壓縮到指定的維度，主要是為了降維和濃縮資訊的功用\n",
    "      - encoder_ffn_embed_dim 是 RNN 輸出和隱藏狀態的維度(hidden dimension)\n",
    "      - encoder_layers 是 RNN 要疊多少層\n",
    "      - dropout 是決定有多少的機率會將某個節點變為 0，主要是為了防止 overfitting ，一般來說是在訓練時使用，測試時則不使用\n",
    "  - *dictionary*: fairseq 幫我們做好的 dictionary. 在此用來得到 padding index，好用來得到 encoder padding mask. \n",
    "  - *embed_tokens*: 事先做好的詞嵌入 (nn.Embedding)\n",
    "\n",
    "- 輸入: \n",
    "    - *src_tokens*: 英文的整數序列 e.g. 1, 28, 29, 205, 2 \n",
    "- 輸出: \n",
    "    - *outputs*: 最上層 RNN 每個 timestep 的輸出，後續可以用 Attention 再進行處理\n",
    "    - *final_hiddens*: 每層最終 timestep 的隱藏狀態，將傳遞到 Decoder 進行解碼\n",
    "    - *encoder_padding_mask*: 告訴我們哪些是位置的資訊不重要。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "S77Kf9Lh6Lnm"
   },
   "outputs": [],
   "source": [
    "class RNNEncoder(FairseqEncoder):\n",
    "    def __init__(self, args, dictionary, embed_tokens):\n",
    "        super().__init__(dictionary)\n",
    "        self.embed_tokens = embed_tokens\n",
    "        \n",
    "        self.embed_dim = args.encoder_embed_dim\n",
    "        self.hidden_dim = args.encoder_ffn_embed_dim\n",
    "        self.num_layers = args.encoder_layers\n",
    "        \n",
    "        self.dropout_in_module = nn.Dropout(args.dropout)\n",
    "        self.rnn = nn.GRU(\n",
    "            self.embed_dim, \n",
    "            self.hidden_dim, \n",
    "            self.num_layers, \n",
    "            dropout=args.dropout, \n",
    "            batch_first=False, \n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.dropout_out_module = nn.Dropout(args.dropout)\n",
    "        \n",
    "        self.padding_idx = dictionary.pad()\n",
    "        \n",
    "    def combine_bidir(self, outs, bsz: int):\n",
    "        out = outs.view(self.num_layers, 2, bsz, -1).transpose(1, 2).contiguous()\n",
    "        return out.view(self.num_layers, bsz, -1)\n",
    "\n",
    "    def forward(self, src_tokens, **unused):\n",
    "        bsz, seqlen = src_tokens.size()\n",
    "        \n",
    "        # get embeddings\n",
    "        x = self.embed_tokens(src_tokens)\n",
    "        x = self.dropout_in_module(x)\n",
    "\n",
    "        # B x T x C -> T x B x C\n",
    "        x = x.transpose(0, 1)\n",
    "        \n",
    "        # 過雙向RNN\n",
    "        h0 = x.new_zeros(2 * self.num_layers, bsz, self.hidden_dim)\n",
    "        x, final_hiddens = self.rnn(x, h0)\n",
    "        outputs = self.dropout_out_module(x)\n",
    "        # outputs = [sequence len, batch size, hid dim * directions] 是最上層RNN的輸出\n",
    "        # hidden =  [num_layers * directions, batch size  , hid dim]\n",
    "        \n",
    "        # 因為 Encoder 是雙向的RNN，所以需要將同一層兩個方向的 hidden state 接在一起\n",
    "        final_hiddens = self.combine_bidir(final_hiddens, bsz)\n",
    "        # hidden =  [num_layers x batch x num_directions*hidden]\n",
    "        \n",
    "        encoder_padding_mask = src_tokens.eq(self.padding_idx).t()\n",
    "        return tuple(\n",
    "            (\n",
    "                outputs,  # seq_len x batch x hidden\n",
    "                final_hiddens,  # num_layers x batch x num_directions*hidden\n",
    "                encoder_padding_mask,  # seq_len x batch\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def reorder_encoder_out(self, encoder_out, new_order):\n",
    "        # 這個beam search時會用到，意義並不是很重要\n",
    "        return tuple(\n",
    "            (\n",
    "                encoder_out[0].index_select(1, new_order),\n",
    "                encoder_out[1].index_select(1, new_order),\n",
    "                encoder_out[2].index_select(1, new_order),\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OED0eZGO6Lnn"
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO5n58YU6Lnn"
   },
   "source": [
    "- 當輸入過長，或是單獨靠 “content vector” 無法取得整個輸入的意思時，用 Attention Mechanism 來提供 Decoder 更多的資訊\n",
    "- 根據現在 **Decoder embeddings** ，去計算在 **Encoder outputs** 中，那些與其有較高的關係，根據關係的數值來把 Encoder outputs 平均起來作為 **Decoder** RNN 的輸入 \n",
    "- 常見 Attention 的實作是用 Neural Network / Dot Product 來算 **query** (decoder embeddings) 和 **key** (Encoder outputs) 之間的關係，再對所有算出來的數值做 **softmax** 得到分佈，最後根據這個分佈對 **values** (Encoder outputs) 做 **weight sum**\n",
    "\n",
    "- 參數:\n",
    "  - *input_embed_dim*: key 的維度，應是 decoder 要做 attend 時的向量的維度\n",
    "  - *source_embed_dim*: query 的維度，應是要被 attend 的向量(encoder outputs)的維度\n",
    "  - *output_embed_dim*: value 的維度，應是做完 attention 後，下一層預期的向量維度\n",
    "\n",
    "- 輸入: \n",
    "    - *inputs*: 就是 key，要 attend 別人的向量\n",
    "    - *encoder_outputs*: 是 query/value，被 attend 的向量\n",
    "    - *encoder_padding_mask*: 告訴我們哪些是位置的資訊不重要。\n",
    "- 輸出: \n",
    "    - *output*: 做完 attention 後的 context vector\n",
    "    - *attention score*: attention 的分布\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "NhsCi9Lg6Lnn"
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_embed_dim, source_embed_dim, output_embed_dim, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_proj = nn.Linear(input_embed_dim, source_embed_dim, bias=bias)\n",
    "        self.output_proj = nn.Linear(\n",
    "            input_embed_dim + source_embed_dim, output_embed_dim, bias=bias\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, encoder_outputs, encoder_padding_mask):\n",
    "        # inputs: T, B, dim\n",
    "        # encoder_outputs: S x B x dim\n",
    "        # padding mask:  S x B\n",
    "        \n",
    "        # convert all to batch first\n",
    "        inputs = inputs.transpose(1,0) # B, T, dim\n",
    "        encoder_outputs = encoder_outputs.transpose(1,0) # B, S, dim\n",
    "        encoder_padding_mask = encoder_padding_mask.transpose(1,0) # B, S\n",
    "        \n",
    "        # 投影到encoder_outputs的維度\n",
    "        x = self.input_proj(inputs)\n",
    "\n",
    "        # 計算attention\n",
    "        # (B, T, dim) x (B, dim, S) = (B, T, S)\n",
    "        attn_scores = torch.bmm(x, encoder_outputs.transpose(1,2))\n",
    "\n",
    "        # 擋住padding位置的attention\n",
    "        if encoder_padding_mask is not None:\n",
    "            # 利用broadcast  B, S -> (B, 1, S)\n",
    "            encoder_padding_mask = encoder_padding_mask.unsqueeze(1)\n",
    "            attn_scores = (\n",
    "                attn_scores.float()\n",
    "                .masked_fill_(encoder_padding_mask, float(\"-inf\"))\n",
    "                .type_as(attn_scores)\n",
    "            )  # FP16 support: cast to float and back\n",
    "\n",
    "        # 在source對應維度softmax\n",
    "        attn_scores = F.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        # 形狀 (B, T, S) x (B, S, dim) = (B, T, dim) 加權平均\n",
    "        x = torch.bmm(attn_scores, encoder_outputs)\n",
    "\n",
    "        # (B, T, dim)\n",
    "        x = torch.cat((x, inputs), dim=-1)\n",
    "        x = torch.tanh(self.output_proj(x)) # concat + linear + tanh\n",
    "        \n",
    "        # 回復形狀 (B, T, dim) -> (T, B, dim)\n",
    "        return x.transpose(1,0), attn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNiRpSCs6Lnn"
   },
   "source": [
    "## Decoder 解碼器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulyJzWGE6Lnn"
   },
   "source": [
    "* 解碼器的 hidden states 會用編碼器最終隱藏狀態來初始化(content vector)\n",
    "* 解碼器同時也根據目前 timestep 的輸入(也就是前幾個 timestep 的 output)，改變 hidden states，並輸出結果 \n",
    "* 如果加入 attention 可以使表現更好\n",
    "* 我們把 seq2seq 步驟寫在解碼器裡，好讓等等 Seq2Seq 這個型別可以通用 RNN 和 Transformer，而不用再改寫\n",
    "- 參數:\n",
    "  - *args*\n",
    "      - decoder_embed_dim 是解碼器 embedding 的維度，類同 encoder_embed_dim，\n",
    "      - decoder_ffn_embed_dim 是解碼器 RNN 的隱藏維度，類同 encoder_ffn_embed_dim\n",
    "      - decoder_layers 解碼器 RNN 的層數\n",
    "      - share_decoder_input_output_embed 通常 decoder 最後輸出的投影矩陣會和輸入 embedding 共用參數\n",
    "  - *dictionary*: fairseq 幫我們做好的 dictionary.\n",
    "  - *embed_tokens*: 事先做好的詞嵌入(nn.Embedding)\n",
    "- 輸入: \n",
    "    - *prev_output_tokens*: 英文的整數序列 e.g. 1, 28, 29, 205, 2 已經 shift 一格的 target\n",
    "    - *encoder_out*: 編碼器的輸出\n",
    "    - *incremental_state*: 這是測試階段為了加速，所以會記錄每個 timestep 的 hidden state 詳見 forward\n",
    "- 輸出: \n",
    "    - *outputs*: decoder 每個 timestep 的 logits，還沒經過 softmax 的分布\n",
    "    - *extra*: 沒用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Jbw97QO26Lnn"
   },
   "outputs": [],
   "source": [
    "class RNNDecoder(FairseqIncrementalDecoder):\n",
    "    def __init__(self, args, dictionary, embed_tokens):\n",
    "        super().__init__(dictionary)\n",
    "        self.embed_tokens = embed_tokens\n",
    "        \n",
    "        assert args.decoder_layers == args.encoder_layers, f\"\"\"seq2seq rnn requires that encoder \n",
    "        and decoder have same layers of rnn. got: {args.encoder_layers, args.decoder_layers}\"\"\"\n",
    "        assert args.decoder_ffn_embed_dim == args.encoder_ffn_embed_dim*2, f\"\"\"seq2seq-rnn requires \n",
    "        that decoder hidden to be 2*encoder hidden dim. got: {args.decoder_ffn_embed_dim, args.encoder_ffn_embed_dim*2}\"\"\"\n",
    "        \n",
    "        self.embed_dim = args.decoder_embed_dim\n",
    "        self.hidden_dim = args.decoder_ffn_embed_dim\n",
    "        self.num_layers = args.decoder_layers\n",
    "        \n",
    "        \n",
    "        self.dropout_in_module = nn.Dropout(args.dropout)\n",
    "        self.rnn = nn.GRU(\n",
    "            self.embed_dim, \n",
    "            self.hidden_dim, \n",
    "            self.num_layers, \n",
    "            dropout=args.dropout, \n",
    "            batch_first=False, \n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.attention = AttentionLayer(\n",
    "            self.embed_dim, self.hidden_dim, self.embed_dim, bias=False\n",
    "        ) \n",
    "        # self.attention = None\n",
    "        self.dropout_out_module = nn.Dropout(args.dropout)\n",
    "        \n",
    "        if self.hidden_dim != self.embed_dim:\n",
    "            self.project_out_dim = nn.Linear(self.hidden_dim, self.embed_dim)\n",
    "        else:\n",
    "            self.project_out_dim = None\n",
    "        \n",
    "        if args.share_decoder_input_output_embed:\n",
    "            self.output_projection = nn.Linear(\n",
    "                self.embed_tokens.weight.shape[1],\n",
    "                self.embed_tokens.weight.shape[0],\n",
    "                bias=False,\n",
    "            )\n",
    "            self.output_projection.weight = self.embed_tokens.weight\n",
    "        else:\n",
    "            self.output_projection = nn.Linear(\n",
    "                self.output_embed_dim, len(dictionary), bias=False\n",
    "            )\n",
    "            nn.init.normal_(\n",
    "                self.output_projection.weight, mean=0, std=self.output_embed_dim ** -0.5\n",
    "            )\n",
    "        \n",
    "    def forward(self, prev_output_tokens, encoder_out, incremental_state=None, **unused):\n",
    "        # 取出encoder的輸出\n",
    "        encoder_outputs, encoder_hiddens, encoder_padding_mask = encoder_out\n",
    "        # outputs:          seq_len x batch x num_directions*hidden\n",
    "        # encoder_hiddens:  num_layers x batch x num_directions*encoder_hidden\n",
    "        # padding_mask:     seq_len x batch\n",
    "        \n",
    "        if incremental_state is not None and len(incremental_state) > 0:\n",
    "            # 有上個timestep留下的資訊，讀進來就可以繼續decode，不用從bos重來\n",
    "            prev_output_tokens = prev_output_tokens[:, -1:]\n",
    "            cache_state = self.get_incremental_state(incremental_state, \"cached_state\")\n",
    "            prev_hiddens = cache_state[\"prev_hiddens\"]\n",
    "        else:\n",
    "            # 沒有incremental state代表這是training或者是test time時的第一步\n",
    "            # 準備seq2seq: 把encoder_hiddens pass進去decoder的hidden states\n",
    "            prev_hiddens = encoder_hiddens\n",
    "        \n",
    "        bsz, seqlen = prev_output_tokens.size()\n",
    "        \n",
    "        # embed tokens\n",
    "        x = self.embed_tokens(prev_output_tokens)\n",
    "        x = self.dropout_in_module(x)\n",
    "\n",
    "        # B x T x C -> T x B x C\n",
    "        x = x.transpose(0, 1)\n",
    "                \n",
    "        # 做decoder-to-encoder attention\n",
    "        if self.attention is not None:\n",
    "            x, attn = self.attention(x, encoder_outputs, encoder_padding_mask)\n",
    "                        \n",
    "        # 過單向RNN\n",
    "        x, final_hiddens = self.rnn(x, prev_hiddens)\n",
    "        # outputs = [sequence len, batch size, hid dim]\n",
    "        # hidden =  [num_layers * directions, batch size  , hid dim]\n",
    "        x = self.dropout_out_module(x)\n",
    "                \n",
    "        # 投影到embedding size (如果hidden 和embed size不一樣，然後share_embedding又設成True,需要額外project一次)\n",
    "        if self.project_out_dim != None:\n",
    "            x = self.project_out_dim(x)\n",
    "        \n",
    "        # 投影到vocab size 的分佈\n",
    "        x = self.output_projection(x)\n",
    "        \n",
    "        # T x B x C -> B x T x C\n",
    "        x = x.transpose(1, 0)\n",
    "        \n",
    "        # 如果是Incremental, 記錄這個timestep的hidden states, 下個timestep讀回來\n",
    "        cache_state = {\n",
    "            \"prev_hiddens\": final_hiddens,\n",
    "        }\n",
    "        self.set_incremental_state(incremental_state, \"cached_state\", cache_state)\n",
    "        \n",
    "        return x, None\n",
    "    \n",
    "    def reorder_incremental_state(\n",
    "        self,\n",
    "        incremental_state,\n",
    "        new_order,\n",
    "    ):\n",
    "        # 這個beam search時會用到，意義並不是很重要\n",
    "        cache_state = self.get_incremental_state(incremental_state, \"cached_state\")\n",
    "        prev_hiddens = cache_state[\"prev_hiddens\"]\n",
    "        prev_hiddens = [p.index_select(0, new_order) for p in prev_hiddens]\n",
    "        cache_state = {\n",
    "            \"prev_hiddens\": torch.stack(prev_hiddens),\n",
    "        }\n",
    "        self.set_incremental_state(incremental_state, \"cached_state\", cache_state)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrD3mA1i6Lno"
   },
   "source": [
    "## Seq2Seq\n",
    "- 由 **Encoder** 和 **Decoder** 組成\n",
    "- 接收輸入並傳給 **Encoder** \n",
    "- 將 **Encoder** 的輸出傳給 **Decoder**\n",
    "- **Decoder** 根據前幾個 timestep 的輸出和 **Encoder** 輸出進行解碼  \n",
    "- 當解碼完成後，將 **Decoder** 的輸出傳回 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "V-9JK5XV6Lno"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(FairseqEncoderDecoderModel):\n",
    "    def __init__(self, args, encoder, decoder):\n",
    "        super().__init__(encoder, decoder)\n",
    "        self.args = args\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        src_tokens,\n",
    "        src_lengths,\n",
    "        prev_output_tokens,\n",
    "        return_all_hiddens: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Run the forward pass for an encoder-decoder model.\n",
    "        \"\"\"\n",
    "        encoder_out = self.encoder(\n",
    "            src_tokens, src_lengths=src_lengths, return_all_hiddens=return_all_hiddens\n",
    "        )\n",
    "        logits, extra = self.decoder(\n",
    "            prev_output_tokens,\n",
    "            encoder_out=encoder_out,\n",
    "            src_lengths=src_lengths,\n",
    "            return_all_hiddens=return_all_hiddens,\n",
    "        )\n",
    "        return logits, extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb5lkANz6Lno"
   },
   "source": [
    "# 模型初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uBmYoQlD6Lno"
   },
   "outputs": [],
   "source": [
    "# # HINT: transformer 架構\n",
    "from fairseq.models.transformer import (\n",
    "    TransformerEncoder, \n",
    "    TransformerDecoder,\n",
    "    \n",
    ")\n",
    "\n",
    "def build_model(args, task):\n",
    "    \"\"\" 按照參數設定建置模型 \"\"\"\n",
    "    src_dict, tgt_dict = task.source_dictionary, task.target_dictionary\n",
    "\n",
    "    # 詞嵌入\n",
    "    encoder_embed_tokens = nn.Embedding(len(src_dict), args.encoder_embed_dim, src_dict.pad())\n",
    "    decoder_embed_tokens = nn.Embedding(len(tgt_dict), args.decoder_embed_dim, tgt_dict.pad())\n",
    "    \n",
    "    # 編碼器與解碼器\n",
    "    # TODO: 替換成 TransformerEncoder 和 TransformerDecoder\n",
    "    encoder = TransformerEncoder(args, src_dict, encoder_embed_tokens)\n",
    "    decoder = TransformerDecoder(args, tgt_dict, decoder_embed_tokens)\n",
    "    \n",
    "    # 序列到序列模型\n",
    "    model = Seq2Seq(args, encoder, decoder)\n",
    "    \n",
    "    # 序列到序列模型的初始化很重要 需要特別處理\n",
    "    def init_params(module):\n",
    "        from fairseq.modules import MultiheadAttention\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        if isinstance(module, MultiheadAttention):\n",
    "            module.q_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            module.k_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            module.v_proj.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        if isinstance(module, nn.RNNBase):\n",
    "            for name, param in module.named_parameters():\n",
    "                if \"weight\" in name or \"bias\" in name:\n",
    "                    param.data.uniform_(-0.1, 0.1)\n",
    "            \n",
    "    # 初始化模型\n",
    "    model.apply(init_params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qMAsfxb6Lno"
   },
   "source": [
    "## 設定模型相關參數\n",
    "參考參數\n",
    "\n",
    "|model|embedding dim|encoder ffn|encoder layers|decoder ffn|decoder layers|\n",
    "|-|-|-|-|-|-|\n",
    "|RNN|256|512|1|1024|1|\n",
    "|Transformer|256|1024|4|1024|4|\n",
    "\n",
    "Strong baseline 用的參數可以參考 [Attention is all you need](#vaswani2017) 的 Table 3 的 transformer-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "fQVcPDv86Lno"
   },
   "outputs": [],
   "source": [
    "arch_args = Namespace(\n",
    "    encoder_embed_dim=512,\n",
    "    encoder_ffn_embed_dim=2048,\n",
    "    encoder_layers=6,\n",
    "    decoder_embed_dim=512,\n",
    "    decoder_ffn_embed_dim=2048,\n",
    "    decoder_layers=6,\n",
    "    share_decoder_input_output_embed=True,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "# # HINT: 補上Transformer用的參數\n",
    "def add_transformer_args(args):\n",
    "    args.encoder_attention_heads=8\n",
    "    args.encoder_normalize_before=True\n",
    "    \n",
    "    args.decoder_attention_heads=8\n",
    "    args.decoder_normalize_before=True\n",
    "    \n",
    "    args.activation_fn=\"relu\"\n",
    "    args.max_source_positions=1024\n",
    "    args.max_target_positions=1024\n",
    "    \n",
    "    # 補上我們沒有設定的Transformer預設參數\n",
    "    from fairseq.models.transformer import base_architecture \n",
    "    base_architecture(arch_args)\n",
    "\n",
    "add_transformer_args(arch_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "FwyxZxaa6Lnp"
   },
   "outputs": [],
   "source": [
    "if config.use_wandb:\n",
    "    wandb.config.update(vars(arch_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "hg8piqWc6Lnp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:44:36 | INFO | hw5.seq2seq | Seq2Seq(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(8000, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(8000, 512, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (output_projection): Linear(in_features=512, out_features=8000, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = build_model(arch_args, task)\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPFxCKJ_6Lnp"
   },
   "source": [
    "# Optimization 最佳化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgVI30rw6Lnp"
   },
   "source": [
    "## Loss: Label Smoothing Regularization\n",
    "* 讓模型學習輸出較不集中的分佈，防止模型過度自信\n",
    "* 有時候Ground Truth並非唯一答案，所以在算loss時，我們會保留一部份機率給正確答案以外的label\n",
    "* 可以有效防止過度擬合\n",
    "\n",
    "code [source](https://fairseq.readthedocs.io/en/latest/_modules/fairseq/criterions/label_smoothed_cross_entropy.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "W2vo23Rb6Lnp"
   },
   "outputs": [],
   "source": [
    "class LabelSmoothedCrossEntropyCriterion(nn.Module):\n",
    "    def __init__(self, smoothing, ignore_index=None, reduce=True):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduce = reduce\n",
    "    \n",
    "    def forward(self, lprobs, target):\n",
    "        if target.dim() == lprobs.dim() - 1:\n",
    "            target = target.unsqueeze(-1)\n",
    "        # nll: Negative log likelihood，當目標是one-hot時的cross-entropy loss. 以下同 F.nll_loss\n",
    "        nll_loss = -lprobs.gather(dim=-1, index=target)\n",
    "        # 將一部分正確答案的機率分配給其他label 所以當計算cross-entropy時等於把所有label的log prob加起來\n",
    "        smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n",
    "        if self.ignore_index is not None:\n",
    "            pad_mask = target.eq(self.ignore_index)\n",
    "            nll_loss.masked_fill_(pad_mask, 0.0)\n",
    "            smooth_loss.masked_fill_(pad_mask, 0.0)\n",
    "        else:\n",
    "            nll_loss = nll_loss.squeeze(-1)\n",
    "            smooth_loss = smooth_loss.squeeze(-1)\n",
    "        if self.reduce:\n",
    "            nll_loss = nll_loss.sum()\n",
    "            smooth_loss = smooth_loss.sum()\n",
    "        # 計算cross-entropy時 加入分配給其他label的loss\n",
    "        eps_i = self.smoothing / lprobs.size(-1)\n",
    "        loss = (1.0 - self.smoothing) * nll_loss + eps_i * smooth_loss\n",
    "        return loss\n",
    "\n",
    "# 一般都用0.1效果就很好了\n",
    "criterion = LabelSmoothedCrossEntropyCriterion(\n",
    "    smoothing=0.1,\n",
    "    ignore_index=task.target_dictionary.pad(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDv8RoXS6Lnp"
   },
   "source": [
    "## Optimizer: Adam + lr scheduling\n",
    "Inverse square root 排程對於訓練 Transformer 時的穩定性很重要，後來也用在 RNN 上。\n",
    "根據底下公式來更新 learning rate，前期線性增長，後期根據更新步數方根的倒數來遞減。\n",
    "$$lrate = d_{\\text{model}}^{-0.5}\\cdot\\min({step\\_num}^{-0.5},{step\\_num}\\cdot{warmup\\_steps}^{-1.5})$$\n",
    "code [source](https://nlp.seas.harvard.edu/2018/04/03/attention.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "_gKUjQse6Lnp"
   },
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "    \n",
    "    @property\n",
    "    def param_groups(self):\n",
    "        return self.optimizer.param_groups\n",
    "        \n",
    "    def multiply_grads(self, c):\n",
    "        \"\"\"Multiplies grads by a constant *c*.\"\"\"                \n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is not None:\n",
    "                    p.grad.data.mul_(c)\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return 0 if not step else self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIBi8Axw6Lnq"
   },
   "source": [
    "## 排程視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "HuBQSK7u6Lnq"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = NoamOpt(\n",
    "    model_size=arch_args.encoder_embed_dim, \n",
    "    factor=config.lr_factor, \n",
    "    warmup=config.lr_warmup, \n",
    "    optimizer=torch.optim.AdamW(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.0001))\n",
    "plt.plot(np.arange(1, 100000), [optimizer.rate(i) for i in range(1, 100000)])\n",
    "plt.legend([f\"{optimizer.model_size}:{optimizer.warmup}\"])\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRiUpnqO6Lnq"
   },
   "source": [
    "# 訓練步驟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4A1N6YC6Lnq"
   },
   "source": [
    "## Training 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "gBeUOPYO6Lnq"
   },
   "outputs": [],
   "source": [
    "from fairseq.data import iterators\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "def train_one_epoch(epoch_itr, model, task, criterion, optimizer, accum_steps=1):\n",
    "    itr = epoch_itr.next_epoch_itr(shuffle=True)\n",
    "    itr = iterators.GroupedIterator(itr, accum_steps) # 梯度累積: 每 accum_steps 個 sample 更新一次\n",
    "    \n",
    "    stats = {\"loss\": []}\n",
    "    scaler = GradScaler() # 混和精度訓練 automatic mixed precision (amp) \n",
    "    \n",
    "    model.train()\n",
    "    progress = tqdm(itr, desc=f\"train epoch {epoch_itr.epoch}\", leave=False)\n",
    "    for samples in progress:\n",
    "        model.zero_grad()\n",
    "        accum_loss = 0\n",
    "        sample_size = 0\n",
    "        # 梯度累積: 每 accum_steps 個 sample 更新一次\n",
    "        for i, sample in enumerate(samples):\n",
    "            if i == 1:\n",
    "                # emptying the CUDA cache after the first step can reduce the chance of OOM\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            sample = utils.move_to_cuda(sample, device=device)\n",
    "            target = sample[\"target\"]\n",
    "            sample_size_i = sample[\"ntokens\"]\n",
    "            sample_size += sample_size_i\n",
    "            \n",
    "            # 混和精度訓練 \n",
    "            with autocast():\n",
    "                net_output = model.forward(**sample[\"net_input\"])\n",
    "                lprobs = F.log_softmax(net_output[0], -1)            \n",
    "                loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1))\n",
    "                \n",
    "                # logging\n",
    "                accum_loss += loss.item()\n",
    "                # back-prop\n",
    "                scaler.scale(loss).backward()                \n",
    "        \n",
    "        scaler.unscale_(optimizer)\n",
    "        optimizer.multiply_grads(1 / (sample_size or 1.0)) # (sample_size or 1.0) handles the case of a zero gradient\n",
    "        gnorm = nn.utils.clip_grad_norm_(model.parameters(), config.clip_norm) # 梯度裁剪 防止梯度爆炸\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # logging\n",
    "        loss_print = accum_loss/sample_size\n",
    "        stats[\"loss\"].append(loss_print)\n",
    "        progress.set_postfix(loss=loss_print)\n",
    "        if config.use_wandb:\n",
    "            wandb.log({\n",
    "                \"train/loss\": loss_print,\n",
    "                \"train/grad_norm\": gnorm.item(),\n",
    "                \"train/lr\": optimizer.rate(),\n",
    "                \"train/sample_size\": sample_size,\n",
    "            })\n",
    "        \n",
    "    loss_print = np.mean(stats[\"loss\"])\n",
    "    logger.info(f\"training loss: {loss_print:.4f}\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkvSlxl_6Lnq"
   },
   "source": [
    "## Validation & Inference 檢驗和推論\n",
    "為防止訓練發生過度擬合，每過一段時間要做一次檢測，計算模型在未看過的資料上的表現。\n",
    "- 過程基本上和training一樣，另外加上 inference\n",
    "- 檢驗完畢可順便儲存模型參數\n",
    "\n",
    "單看 validation loss，我們很難知道模型真實的效能\n",
    "- 直接用當前模型去生成翻譯結果 (hypothesis)，再和正確答案 (reference) 計算 BLEU score\n",
    "- 也可用肉眼看翻譯結果的好壞\n",
    "- 我們用 fairseq 寫好的 sequence generator 來進行 beam search 生成翻譯結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "B8v95s_b6Lnq"
   },
   "outputs": [],
   "source": [
    "# fairseq 的 beam search generator\n",
    "# 給定模型和輸入序列，用 beam search 生成翻譯結果\n",
    "sequence_generator = task.build_generator([model], config)\n",
    "\n",
    "def decode(toks, dictionary):\n",
    "    # 從 Tensor 轉成人看得懂的句子\n",
    "    s = dictionary.string(\n",
    "        toks.int().cpu(),\n",
    "        config.post_process,\n",
    "    )\n",
    "    return s if s else \"<unk>\"\n",
    "\n",
    "def inference_step(sample, model):\n",
    "    gen_out = sequence_generator.generate([model], sample)\n",
    "    srcs = []\n",
    "    hyps = []\n",
    "    refs = []\n",
    "    for i in range(len(gen_out)):\n",
    "        # 對於每個 sample, 收集輸入，輸出和參考答案，稍後計算 BLEU\n",
    "        srcs.append(decode(\n",
    "            utils.strip_pad(sample[\"net_input\"][\"src_tokens\"][i], task.source_dictionary.pad()), \n",
    "            task.source_dictionary,\n",
    "        ))\n",
    "        hyps.append(decode(\n",
    "            gen_out[i][0][\"tokens\"], # 0 代表取出 beam 內分數第一的輸出結果\n",
    "            task.target_dictionary,\n",
    "        ))\n",
    "        refs.append(decode(\n",
    "            utils.strip_pad(sample[\"target\"][i], task.target_dictionary.pad()), \n",
    "            task.target_dictionary,\n",
    "        ))\n",
    "    return srcs, hyps, refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "mY4NQoaK6Lnr"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sacrebleu\n",
    "\n",
    "def validate(model, task, criterion, log_to_wandb=True):\n",
    "    logger.info('begin validation')\n",
    "    itr = load_data_iterator(task, \"valid\", 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n",
    "    \n",
    "    stats = {\"loss\":[], \"bleu\": 0, \"srcs\":[], \"hyps\":[], \"refs\":[]}\n",
    "    srcs = []\n",
    "    hyps = []\n",
    "    refs = []\n",
    "    \n",
    "    model.eval()\n",
    "    progress = tqdm(itr, desc=f\"validation\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(progress):\n",
    "            # validation loss\n",
    "            sample = utils.move_to_cuda(sample, device=device)\n",
    "            net_output = model.forward(**sample[\"net_input\"])\n",
    "\n",
    "            lprobs = F.log_softmax(net_output[0], -1)\n",
    "            target = sample[\"target\"]\n",
    "            sample_size = sample[\"ntokens\"]\n",
    "            loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1)) / sample_size\n",
    "            progress.set_postfix(valid_loss=loss.item())\n",
    "            stats[\"loss\"].append(loss)\n",
    "            \n",
    "            # 進行推論\n",
    "            s, h, r = inference_step(sample, model)\n",
    "            srcs.extend(s)\n",
    "            hyps.extend(h)\n",
    "            refs.extend(r)\n",
    "            \n",
    "    tok = 'zh' if task.cfg.target_lang == 'zh' else '13a'\n",
    "    stats[\"loss\"] = torch.stack(stats[\"loss\"]).mean().item()\n",
    "    stats[\"bleu\"] = sacrebleu.corpus_bleu(hyps, [refs], tokenize=tok) # 計算BLEU score\n",
    "    stats[\"srcs\"] = srcs\n",
    "    stats[\"hyps\"] = hyps\n",
    "    stats[\"refs\"] = refs\n",
    "    \n",
    "    if config.use_wandb and log_to_wandb:\n",
    "        wandb.log({\n",
    "            \"valid/loss\": stats[\"loss\"],\n",
    "            \"valid/bleu\": stats[\"bleu\"].score,\n",
    "        }, commit=False)\n",
    "    \n",
    "    showid = np.random.randint(len(hyps))\n",
    "    logger.info(\"example source: \" + srcs[showid])\n",
    "    logger.info(\"example hypothesis: \" + hyps[showid])\n",
    "    logger.info(\"example reference: \" + refs[showid])\n",
    "    \n",
    "    # show bleu results\n",
    "    logger.info(f\"validation loss:\\t{stats['loss']:.4f}\")\n",
    "    logger.info(stats[\"bleu\"].format())\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFx4E8YR6Lnr"
   },
   "source": [
    "# 儲存及載入模型參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "4gwMrlbA6Lnr"
   },
   "outputs": [],
   "source": [
    "def validate_and_save(model, task, criterion, optimizer, epoch, save=True):   \n",
    "    stats = validate(model, task, criterion)\n",
    "    bleu = stats['bleu']\n",
    "    loss = stats['loss']\n",
    "    if save:\n",
    "        # save epoch checkpoints\n",
    "        savedir = Path(config.savedir).absolute()\n",
    "        savedir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        check = {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"stats\": {\"bleu\": bleu.score, \"loss\": loss},\n",
    "            \"optim\": {\"step\": optimizer._step}\n",
    "        }\n",
    "        torch.save(check, savedir/f\"checkpoint{epoch}.pt\")\n",
    "        shutil.copy(savedir/f\"checkpoint{epoch}.pt\", savedir/f\"checkpoint_last.pt\")\n",
    "        logger.info(f\"saved epoch checkpoint: {savedir}/checkpoint{epoch}.pt\")\n",
    "    \n",
    "        # save epoch samples\n",
    "        with open(savedir/f\"samples{epoch}.{config.source_lang}-{config.target_lang}.txt\", \"w\") as f:\n",
    "            for s, h in zip(stats[\"srcs\"], stats[\"hyps\"]):\n",
    "                f.write(f\"{s}\\t{h}\\n\")\n",
    "\n",
    "        # get best valid bleu    \n",
    "        if getattr(validate_and_save, \"best_bleu\", 0) < bleu.score:\n",
    "            validate_and_save.best_bleu = bleu.score\n",
    "            torch.save(check, savedir/f\"checkpoint_best.pt\")\n",
    "            \n",
    "        del_file = savedir / f\"checkpoint{epoch - config.keep_last_epochs}.pt\"\n",
    "        if del_file.exists():\n",
    "            del_file.unlink()\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def try_load_checkpoint(model, optimizer=None, name=None):\n",
    "    name = name if name else \"checkpoint_last.pt\"\n",
    "    checkpath = Path(config.savedir)/name\n",
    "    if checkpath.exists():\n",
    "        check = torch.load(checkpath)\n",
    "        model.load_state_dict(check[\"model\"])\n",
    "        stats = check[\"stats\"]\n",
    "        step = \"unknown\"\n",
    "        if optimizer != None:\n",
    "            optimizer._step = step = check[\"optim\"][\"step\"]\n",
    "        logger.info(f\"loaded checkpoint {checkpath}: step={step} loss={stats['loss']} bleu={stats['bleu']}\")\n",
    "    else:\n",
    "        logger.info(f\"no checkpoints found at {checkpath}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saulMZdj6Lnr"
   },
   "source": [
    "# 主程式\n",
    "## 訓練迴圈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "tc_ZdjTa6Lnr"
   },
   "outputs": [],
   "source": [
    "model = model.to(device=device)\n",
    "criterion = criterion.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "U31TiHRW6Lnr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 29 15:44:39 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 36%   44C    P2    63W / 250W |   1537MiB / 11016MiB |      8%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  On   | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 42%   43C    P8     1W / 250W |      8MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      8043      G   /usr/lib/xorg/Xorg                 64MiB |\r\n",
      "|    0   N/A  N/A      8380      G   /usr/bin/gnome-shell               16MiB |\r\n",
      "|    0   N/A  N/A    658144      G   /usr/lib/firefox/firefox            3MiB |\r\n",
      "|    0   N/A  N/A    658535      G   /usr/lib/firefox/firefox            3MiB |\r\n",
      "|    0   N/A  N/A    659801      G   /usr/lib/firefox/firefox            3MiB |\r\n",
      "|    0   N/A  N/A    861188      G   /usr/lib/firefox/firefox            3MiB |\r\n",
      "|    0   N/A  N/A   1039172      C   /usr/bin/python3                 1437MiB |\r\n",
      "|    1   N/A  N/A      8043      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A      8380      G   /usr/bin/gnome-shell                0MiB |\r\n",
      "|    1   N/A  N/A    658144      G   /usr/lib/firefox/firefox            0MiB |\r\n",
      "|    1   N/A  N/A    658535      G   /usr/lib/firefox/firefox            0MiB |\r\n",
      "|    1   N/A  N/A    659801      G   /usr/lib/firefox/firefox            0MiB |\r\n",
      "|    1   N/A  N/A    861188      G   /usr/lib/firefox/firefox            0MiB |\r\n",
      "|    1   N/A  N/A   1039172      C   /usr/bin/python3                    0MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "LsPY8P0Q6Lnr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:45:03 | INFO | hw5.seq2seq | task: TranslationTask\n",
      "2021-04-29 15:45:03 | INFO | hw5.seq2seq | encoder: TransformerEncoder\n",
      "2021-04-29 15:45:03 | INFO | hw5.seq2seq | decoder: TransformerDecoder\n",
      "2021-04-29 15:45:03 | INFO | hw5.seq2seq | criterion: LabelSmoothedCrossEntropyCriterion\n",
      "2021-04-29 15:45:03 | INFO | hw5.seq2seq | optimizer: NoamOpt\n",
      "2021-04-29 15:45:03 | INFO | hw5.seq2seq | num. model params: 52,332,544 (num. trained: 52,332,544)\n",
      "2021-04-29 15:45:03 | INFO | hw5.seq2seq | max tokens per batch = 4096, accumulate steps = 4\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"task: {}\".format(task.__class__.__name__))\n",
    "logger.info(\"encoder: {}\".format(model.encoder.__class__.__name__))\n",
    "logger.info(\"decoder: {}\".format(model.decoder.__class__.__name__))\n",
    "logger.info(\"criterion: {}\".format(criterion.__class__.__name__))\n",
    "logger.info(\"optimizer: {}\".format(optimizer.__class__.__name__))\n",
    "logger.info(\n",
    "    \"num. model params: {:,} (num. trained: {:,})\".format(\n",
    "        sum(p.numel() for p in model.parameters()),\n",
    "        sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "    )\n",
    ")\n",
    "logger.info(f\"max tokens per batch = {config.max_tokens}, accumulate steps = {config.accum_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "tOQY-iY-6Lns",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 22:49:55 | WARNING | fairseq.tasks.fairseq_task | 1 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[326674]\n",
      "2021-04-28 22:49:55 | INFO | hw5.seq2seq | no checkpoints found at checkpoints/rnn/checkpoint_last.pt!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 22:55:08 | INFO | hw5.seq2seq | training loss: 5.5009\n",
      "2021-04-28 22:55:08 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 22:55:51 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-28 22:55:51 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-28 22:55:51 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 22:55:51 | INFO | hw5.seq2seq | example source: 好像大家對人物比較有反應 。\n",
      "2021-04-28 22:55:51 | INFO | hw5.seq2seq | example hypothesis: okay .\n",
      "2021-04-28 22:55:51 | INFO | hw5.seq2seq | example reference: somehow , to people , we're slightly better at responding to that sometimes .\n",
      "2021-04-28 22:55:51 | INFO | hw5.seq2seq | validation loss:\t4.1163\n",
      "2021-04-28 22:55:51 | INFO | hw5.seq2seq | BLEU = 4.22 32.4/7.9/2.4/0.8 (BP = 0.905 ratio = 0.909 hyp_len = 70050 ref_len = 77050)\n",
      "2021-04-28 22:55:52 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint1.pt\n",
      "2021-04-28 22:55:52 | INFO | hw5.seq2seq | end of epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:01:05 | INFO | hw5.seq2seq | training loss: 3.7383\n",
      "2021-04-28 23:01:05 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:01:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-28 23:01:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-28 23:01:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:01:48 | INFO | hw5.seq2seq | example source: 謝謝 。\n",
      "2021-04-28 23:01:48 | INFO | hw5.seq2seq | example hypothesis: thank you very much .\n",
      "2021-04-28 23:01:48 | INFO | hw5.seq2seq | example reference: thank you .\n",
      "2021-04-28 23:01:48 | INFO | hw5.seq2seq | validation loss:\t3.2906\n",
      "2021-04-28 23:01:48 | INFO | hw5.seq2seq | BLEU = 9.68 45.7/16.7/7.4/3.6 (BP = 0.812 ratio = 0.828 hyp_len = 63790 ref_len = 77050)\n",
      "2021-04-28 23:01:48 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint2.pt\n",
      "2021-04-28 23:01:49 | INFO | hw5.seq2seq | end of epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:07:03 | INFO | hw5.seq2seq | training loss: 3.2002\n",
      "2021-04-28 23:07:03 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:07:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-28 23:07:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-28 23:07:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:07:45 | INFO | hw5.seq2seq | example source: 我們仍有許多要努力的地方 。\n",
      "2021-04-28 23:07:45 | INFO | hw5.seq2seq | example hypothesis: we still have a lot of work .\n",
      "2021-04-28 23:07:45 | INFO | hw5.seq2seq | example reference: we have some serious work still to do .\n",
      "2021-04-28 23:07:45 | INFO | hw5.seq2seq | validation loss:\t3.0129\n",
      "2021-04-28 23:07:45 | INFO | hw5.seq2seq | BLEU = 12.67 51.4/21.4/10.5/5.3 (BP = 0.807 ratio = 0.824 hyp_len = 63466 ref_len = 77050)\n",
      "2021-04-28 23:07:46 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint3.pt\n",
      "2021-04-28 23:07:47 | INFO | hw5.seq2seq | end of epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:13:05 | INFO | hw5.seq2seq | training loss: 2.9781\n",
      "2021-04-28 23:13:05 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:13:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-28 23:13:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-28 23:13:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:13:48 | INFO | hw5.seq2seq | example source: 他叫丹尼班賽特 , 23年之後 , 就是這一年也是在丹尼結婚的一年我們第一次通過fda批准一種藥物可精確地修復 \" 囊狀纖維化 \" 的缺陷基於所有對分子的認識的基礎上 。\n",
      "2021-04-28 23:13:48 | INFO | hw5.seq2seq | example hypothesis: he's a year after danny race , and that's what we've been married in danny for the first time , and for the first time , we've approved drugs to a precisely fiber based on all the foundations of molecules .\n",
      "2021-04-28 23:13:48 | INFO | hw5.seq2seq | example reference: that's danny bessette , 23 years later , because this is the year , and it's also the year where danny got married , where we have , for the first time , the approval by the fda of a drug that precisely targets the defect in cystic fibrosis based upon all this molecular understanding .\n",
      "2021-04-28 23:13:48 | INFO | hw5.seq2seq | validation loss:\t2.8761\n",
      "2021-04-28 23:13:48 | INFO | hw5.seq2seq | BLEU = 15.10 53.3/23.7/12.1/6.3 (BP = 0.856 ratio = 0.865 hyp_len = 66649 ref_len = 77050)\n",
      "2021-04-28 23:13:48 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint4.pt\n",
      "2021-04-28 23:13:49 | INFO | hw5.seq2seq | end of epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:19:06 | INFO | hw5.seq2seq | training loss: 2.8618\n",
      "2021-04-28 23:19:06 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:19:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-28 23:19:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-28 23:19:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:19:48 | INFO | hw5.seq2seq | example source: 而我身為一名訓練有素的傳染流行病學家 ,\n",
      "2021-04-28 23:19:48 | INFO | hw5.seq2seq | example hypothesis: i'm a trained epidemiologist .\n",
      "2021-04-28 23:19:48 | INFO | hw5.seq2seq | example reference: now , i'm an infectious disease epidemiologist by training .\n",
      "2021-04-28 23:19:48 | INFO | hw5.seq2seq | validation loss:\t2.7972\n",
      "2021-04-28 23:19:48 | INFO | hw5.seq2seq | BLEU = 15.78 53.4/24.3/12.7/6.9 (BP = 0.859 ratio = 0.868 hyp_len = 66904 ref_len = 77050)\n",
      "2021-04-28 23:19:49 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint5.pt\n",
      "2021-04-28 23:19:50 | INFO | hw5.seq2seq | end of epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:25:07 | INFO | hw5.seq2seq | training loss: 2.7578\n",
      "2021-04-28 23:25:07 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:25:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-28 23:25:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-28 23:25:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:25:48 | INFO | hw5.seq2seq | example source: 我是在開玩笑 。\n",
      "2021-04-28 23:25:48 | INFO | hw5.seq2seq | example hypothesis: i was joking .\n",
      "2021-04-28 23:25:48 | INFO | hw5.seq2seq | example reference: i'm kidding .\n",
      "2021-04-28 23:25:48 | INFO | hw5.seq2seq | validation loss:\t2.7054\n",
      "2021-04-28 23:25:48 | INFO | hw5.seq2seq | BLEU = 17.17 56.4/26.6/14.3/7.9 (BP = 0.845 ratio = 0.856 hyp_len = 65963 ref_len = 77050)\n",
      "2021-04-28 23:25:48 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint6.pt\n",
      "2021-04-28 23:25:49 | INFO | hw5.seq2seq | end of epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:31:05 | INFO | hw5.seq2seq | training loss: 2.6417\n",
      "2021-04-28 23:31:05 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:31:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-28 23:31:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-28 23:31:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:31:48 | INFO | hw5.seq2seq | example source: 就在每棟建築物間\n",
      "2021-04-28 23:31:48 | INFO | hw5.seq2seq | example hypothesis: it's between every building .\n",
      "2021-04-28 23:31:48 | INFO | hw5.seq2seq | example reference: it's between buildings .\n",
      "2021-04-28 23:31:48 | INFO | hw5.seq2seq | validation loss:\t2.6336\n",
      "2021-04-28 23:31:48 | INFO | hw5.seq2seq | BLEU = 18.23 55.1/26.3/14.3/8.0 (BP = 0.902 ratio = 0.907 hyp_len = 69863 ref_len = 77050)\n",
      "2021-04-28 23:31:49 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint7.pt\n",
      "2021-04-28 23:31:50 | INFO | hw5.seq2seq | end of epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:37:05 | INFO | hw5.seq2seq | training loss: 2.5554\n",
      "2021-04-28 23:37:05 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:37:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-28 23:37:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-28 23:37:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:37:48 | INFO | hw5.seq2seq | example source: 城市每平方英里一天會有5到10噸的排放量\n",
      "2021-04-28 23:37:48 | INFO | hw5.seq2seq | example hypothesis: cities have five to 10 tons of emissions per square mile .\n",
      "2021-04-28 23:37:48 | INFO | hw5.seq2seq | example reference: that comes out at five to 10 tons daily per square mile in cities .\n",
      "2021-04-28 23:37:48 | INFO | hw5.seq2seq | validation loss:\t2.5916\n",
      "2021-04-28 23:37:48 | INFO | hw5.seq2seq | BLEU = 18.67 56.5/27.5/15.1/8.5 (BP = 0.884 ratio = 0.890 hyp_len = 68598 ref_len = 77050)\n",
      "2021-04-28 23:37:49 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint8.pt\n",
      "2021-04-28 23:37:49 | INFO | hw5.seq2seq | end of epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:43:02 | INFO | hw5.seq2seq | training loss: 2.4863\n",
      "2021-04-28 23:43:02 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:43:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-28 23:43:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-28 23:43:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:43:44 | INFO | hw5.seq2seq | example source: 他們盡其所能 。\n",
      "2021-04-28 23:43:44 | INFO | hw5.seq2seq | example hypothesis: they do what they can .\n",
      "2021-04-28 23:43:44 | INFO | hw5.seq2seq | example reference: they got to work on what they could do .\n",
      "2021-04-28 23:43:44 | INFO | hw5.seq2seq | validation loss:\t2.5690\n",
      "2021-04-28 23:43:44 | INFO | hw5.seq2seq | BLEU = 19.29 57.7/28.5/15.9/9.2 (BP = 0.871 ratio = 0.879 hyp_len = 67695 ref_len = 77050)\n",
      "2021-04-28 23:43:45 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint9.pt\n",
      "2021-04-28 23:43:45 | INFO | hw5.seq2seq | end of epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:48:59 | INFO | hw5.seq2seq | training loss: 2.4292\n",
      "2021-04-28 23:48:59 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:49:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-28 23:49:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-28 23:49:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:49:42 | INFO | hw5.seq2seq | example source: 這是我們感官的所在 , 我們特別的感官視覺、說話能力、聽覺、嗅覺、味覺 。\n",
      "2021-04-28 23:49:42 | INFO | hw5.seq2seq | example hypothesis: this is where our senses are , our special sensory vision , our capacity , our hearing , our auditory , our smell , our taste .\n",
      "2021-04-28 23:49:42 | INFO | hw5.seq2seq | example reference: it's where our senses are located , our special senses our vision , our speech , our hearing , our smell , our taste .\n",
      "2021-04-28 23:49:42 | INFO | hw5.seq2seq | validation loss:\t2.5505\n",
      "2021-04-28 23:49:42 | INFO | hw5.seq2seq | BLEU = 20.19 58.0/29.1/16.5/9.7 (BP = 0.883 ratio = 0.890 hyp_len = 68547 ref_len = 77050)\n",
      "2021-04-28 23:49:42 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint10.pt\n",
      "2021-04-28 23:49:43 | INFO | hw5.seq2seq | end of epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:55:00 | INFO | hw5.seq2seq | training loss: 2.3796\n",
      "2021-04-28 23:55:00 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:55:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-28 23:55:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-28 23:55:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 23:55:42 | INFO | hw5.seq2seq | example source: 覺得 「 很溫暖 」 的則是平常的2.9倍 ,\n",
      "2021-04-28 23:55:42 | INFO | hw5.seq2seq | example hypothesis: it feels like \" warm \" is 2 . 9 times the normal .\n",
      "2021-04-28 23:55:42 | INFO | hw5.seq2seq | example reference: they're feeling \" warm \" at 2 . 9 times the normal level , and so on .\n",
      "2021-04-28 23:55:42 | INFO | hw5.seq2seq | validation loss:\t2.5328\n",
      "2021-04-28 23:55:42 | INFO | hw5.seq2seq | BLEU = 20.77 57.1/28.7/16.4/9.6 (BP = 0.920 ratio = 0.923 hyp_len = 71137 ref_len = 77050)\n",
      "2021-04-28 23:55:43 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint11.pt\n",
      "2021-04-28 23:55:44 | INFO | hw5.seq2seq | end of epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:01:01 | INFO | hw5.seq2seq | training loss: 2.3372\n",
      "2021-04-29 00:01:01 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:01:44 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 00:01:44 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 00:01:44 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:01:45 | INFO | hw5.seq2seq | example source: 所以我認為好消息是雖然現今世界非常的複雜 , 但你所需做的卻非常簡單 。\n",
      "2021-04-29 00:01:45 | INFO | hw5.seq2seq | example hypothesis: so i think the good news is that while the world is very , very complicated today , what you need to do is very simple .\n",
      "2021-04-29 00:01:45 | INFO | hw5.seq2seq | example reference: so i think the good news is that even though the world is extremely complex , what you need to do is very simple .\n",
      "2021-04-29 00:01:45 | INFO | hw5.seq2seq | validation loss:\t2.5306\n",
      "2021-04-29 00:01:45 | INFO | hw5.seq2seq | BLEU = 20.42 57.2/28.6/16.2/9.4 (BP = 0.914 ratio = 0.918 hyp_len = 70700 ref_len = 77050)\n",
      "2021-04-29 00:01:45 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint12.pt\n",
      "2021-04-29 00:01:45 | INFO | hw5.seq2seq | end of epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:07:01 | INFO | hw5.seq2seq | training loss: 2.2985\n",
      "2021-04-29 00:07:01 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:07:43 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 00:07:43 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 00:07:43 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:07:44 | INFO | hw5.seq2seq | example source: 另一條是離子尾 , 含帶電粒子 , 其方向遵循太陽系內磁場方向 。\n",
      "2021-04-29 00:07:44 | INFO | hw5.seq2seq | example hypothesis: the other one is the ion tail , which contains charged particles , following the magnetic field of the solar system .\n",
      "2021-04-29 00:07:44 | INFO | hw5.seq2seq | example reference: the other one is an ion tail , which is charged particles , and they follow the magnetic field in the solar system .\n",
      "2021-04-29 00:07:44 | INFO | hw5.seq2seq | validation loss:\t2.5236\n",
      "2021-04-29 00:07:44 | INFO | hw5.seq2seq | BLEU = 20.85 57.6/29.1/16.7/9.8 (BP = 0.910 ratio = 0.914 hyp_len = 70411 ref_len = 77050)\n",
      "2021-04-29 00:07:44 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint13.pt\n",
      "2021-04-29 00:07:45 | INFO | hw5.seq2seq | end of epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:13:00 | INFO | hw5.seq2seq | training loss: 2.2643\n",
      "2021-04-29 00:13:00 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:13:41 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 00:13:41 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 00:13:41 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:13:42 | INFO | hw5.seq2seq | example source: 如果鬆開手 , 我會學到更多 , 能以開放和好奇的心態前進 。\n",
      "2021-04-29 00:13:42 | INFO | hw5.seq2seq | example hypothesis: and if i relax , i'm going to learn more about openness and curiosity .\n",
      "2021-04-29 00:13:42 | INFO | hw5.seq2seq | example reference: i learn more when i proceed and loosen my grip and proceed openly with curiosity and wonder .\n",
      "2021-04-29 00:13:42 | INFO | hw5.seq2seq | validation loss:\t2.5263\n",
      "2021-04-29 00:13:42 | INFO | hw5.seq2seq | BLEU = 20.73 57.4/29.0/16.6/9.8 (BP = 0.910 ratio = 0.913 hyp_len = 70384 ref_len = 77050)\n",
      "2021-04-29 00:13:43 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint14.pt\n",
      "2021-04-29 00:13:43 | INFO | hw5.seq2seq | end of epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:18:59 | INFO | hw5.seq2seq | training loss: 2.2325\n",
      "2021-04-29 00:18:59 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:19:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 00:19:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 00:19:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:19:43 | INFO | hw5.seq2seq | example source: 我們的虛擬實境公司vrse在去年拍了15部電影我們從中學到了一些東西\n",
      "2021-04-29 00:19:43 | INFO | hw5.seq2seq | example hypothesis: our virtual reality company , vrse , made 15 movies last year , and we learned something about it .\n",
      "2021-04-29 00:19:43 | INFO | hw5.seq2seq | example reference: we've made 15 films in the last year at our vr company , vrse , and we've learned a few things .\n",
      "2021-04-29 00:19:43 | INFO | hw5.seq2seq | validation loss:\t2.5319\n",
      "2021-04-29 00:19:43 | INFO | hw5.seq2seq | BLEU = 20.66 57.4/29.0/16.5/9.8 (BP = 0.908 ratio = 0.912 hyp_len = 70246 ref_len = 77050)\n",
      "2021-04-29 00:19:44 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint15.pt\n",
      "2021-04-29 00:19:44 | INFO | hw5.seq2seq | end of epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:25:00 | INFO | hw5.seq2seq | training loss: 2.2045\n",
      "2021-04-29 00:25:00 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:25:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 00:25:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 00:25:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:25:43 | INFO | hw5.seq2seq | example source: 因此 , 我就與德國慈善社發起了一個為期三年的計畫 , 我們訓練了30名阿富汗男女 , 我們在喀布爾創建了15個諮詢中心 。\n",
      "2021-04-29 00:25:43 | INFO | hw5.seq2seq | example hypothesis: so i launched a threeyear plan with the german philanthropy , and we trained 30 men and women in afghanistan , and we created 15 consultation centers in kabul .\n",
      "2021-04-29 00:25:43 | INFO | hw5.seq2seq | example reference: so , i was able to launch a threeyear project with caritas germany , and we trained 30 afghan women and men , and we opened 15 counseling centers in kabul .\n",
      "2021-04-29 00:25:43 | INFO | hw5.seq2seq | validation loss:\t2.5315\n",
      "2021-04-29 00:25:43 | INFO | hw5.seq2seq | BLEU = 21.00 57.4/29.0/16.7/9.9 (BP = 0.916 ratio = 0.919 hyp_len = 70815 ref_len = 77050)\n",
      "2021-04-29 00:25:44 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint16.pt\n",
      "2021-04-29 00:25:44 | INFO | hw5.seq2seq | end of epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:31:03 | INFO | hw5.seq2seq | training loss: 2.1775\n",
      "2021-04-29 00:31:03 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:31:47 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 00:31:47 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 00:31:47 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:31:47 | INFO | hw5.seq2seq | example source: 我說過他們是很有冒險精神的人\n",
      "2021-04-29 00:31:47 | INFO | hw5.seq2seq | example hypothesis: i said they were very adventurous people .\n",
      "2021-04-29 00:31:47 | INFO | hw5.seq2seq | example reference: as i said , they were adventurous people .\n",
      "2021-04-29 00:31:47 | INFO | hw5.seq2seq | validation loss:\t2.5360\n",
      "2021-04-29 00:31:47 | INFO | hw5.seq2seq | BLEU = 20.83 57.1/28.8/16.4/9.7 (BP = 0.921 ratio = 0.924 hyp_len = 71207 ref_len = 77050)\n",
      "2021-04-29 00:31:48 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint17.pt\n",
      "2021-04-29 00:31:48 | INFO | hw5.seq2seq | end of epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:37:06 | INFO | hw5.seq2seq | training loss: 2.1525\n",
      "2021-04-29 00:37:06 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:37:48 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 00:37:48 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 00:37:48 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:37:49 | INFO | hw5.seq2seq | example source: 這個主意其實很簡單\n",
      "2021-04-29 00:37:49 | INFO | hw5.seq2seq | example hypothesis: it's a very simple idea .\n",
      "2021-04-29 00:37:49 | INFO | hw5.seq2seq | example reference: the idea is very , very simple .\n",
      "2021-04-29 00:37:49 | INFO | hw5.seq2seq | validation loss:\t2.5480\n",
      "2021-04-29 00:37:49 | INFO | hw5.seq2seq | BLEU = 20.93 58.5/29.7/17.1/10.1 (BP = 0.893 ratio = 0.898 hyp_len = 69220 ref_len = 77050)\n",
      "2021-04-29 00:37:49 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint18.pt\n",
      "2021-04-29 00:37:50 | INFO | hw5.seq2seq | end of epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:43:07 | INFO | hw5.seq2seq | training loss: 2.1302\n",
      "2021-04-29 00:43:07 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:43:50 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 00:43:50 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 00:43:50 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:43:51 | INFO | hw5.seq2seq | example source: 事實上一個在資訊安全業界的朋友幾天前告訴我說這世上只有兩種公司已被駭和還沒被駭\n",
      "2021-04-29 00:43:51 | INFO | hw5.seq2seq | example hypothesis: in fact , a friend of mine in the security industry told me a few days ago that there are only two types of companies in the world that are hacked and unsca\n",
      "2021-04-29 00:43:51 | INFO | hw5.seq2seq | example reference: in fact , a friend of mine from the security industry told me the other day that there are two types of companies in the world: those that know they've been hacked , and those that don't .\n",
      "2021-04-29 00:43:51 | INFO | hw5.seq2seq | validation loss:\t2.5522\n",
      "2021-04-29 00:43:51 | INFO | hw5.seq2seq | BLEU = 20.92 57.9/29.4/16.9/10.0 (BP = 0.905 ratio = 0.909 hyp_len = 70039 ref_len = 77050)\n",
      "2021-04-29 00:43:52 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint19.pt\n",
      "2021-04-29 00:43:52 | INFO | hw5.seq2seq | end of epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:49:11 | INFO | hw5.seq2seq | training loss: 2.1087\n",
      "2021-04-29 00:49:11 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:49:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 00:49:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 00:49:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:49:53 | INFO | hw5.seq2seq | example source: 所以 , 下一次當隱私權受到侵害的人來找你時 , 不要責備他們 , 反之 , 我們應該這樣做:讓我們改變對數位隱私的窠臼觀點 , 以同情心、同理心來回應吧 。\n",
      "2021-04-29 00:49:53 | INFO | hw5.seq2seq | example hypothesis: so the next time a privacy abuse comes to you and doesn't blame them , instead of blaming them , we should do this: let's change the way a digital privacy looks , and let's respond with compassion and empathy .\n",
      "2021-04-29 00:49:53 | INFO | hw5.seq2seq | example reference: so the next time a victim of a privacy violation comes up to you , instead of blaming them , let's do this instead: let's shift our ideas about digital privacy , and let's respond with compassion .\n",
      "2021-04-29 00:49:53 | INFO | hw5.seq2seq | validation loss:\t2.5546\n",
      "2021-04-29 00:49:53 | INFO | hw5.seq2seq | BLEU = 21.03 57.5/29.2/16.8/9.9 (BP = 0.915 ratio = 0.918 hyp_len = 70733 ref_len = 77050)\n",
      "2021-04-29 00:49:54 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint20.pt\n",
      "2021-04-29 00:49:55 | INFO | hw5.seq2seq | end of epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:55:08 | INFO | hw5.seq2seq | training loss: 2.0895\n",
      "2021-04-29 00:55:08 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:55:49 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 00:55:49 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 00:55:49 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 00:55:50 | INFO | hw5.seq2seq | example source: 很多人 , 包括我的媽媽在內 , 都說我瘋了 。\n",
      "2021-04-29 00:55:50 | INFO | hw5.seq2seq | example hypothesis: a lot of people , including my mother , said i was crazy .\n",
      "2021-04-29 00:55:50 | INFO | hw5.seq2seq | example reference: many people , including my mother , said i was crazy .\n",
      "2021-04-29 00:55:50 | INFO | hw5.seq2seq | validation loss:\t2.5692\n",
      "2021-04-29 00:55:50 | INFO | hw5.seq2seq | BLEU = 20.69 58.0/29.3/16.9/9.9 (BP = 0.896 ratio = 0.901 hyp_len = 69398 ref_len = 77050)\n",
      "2021-04-29 00:55:50 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint21.pt\n",
      "2021-04-29 00:55:50 | INFO | hw5.seq2seq | end of epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:01:04 | INFO | hw5.seq2seq | training loss: 2.0699\n",
      "2021-04-29 01:01:04 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:01:45 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 01:01:45 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 01:01:45 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:01:46 | INFO | hw5.seq2seq | example source: 而應該將主要精力放在知識創造上 。\n",
      "2021-04-29 01:01:46 | INFO | hw5.seq2seq | example hypothesis: and we should focus primarily on creating knowledge .\n",
      "2021-04-29 01:01:46 | INFO | hw5.seq2seq | example reference: they should be dedicated mainly to knowledge production .\n",
      "2021-04-29 01:01:46 | INFO | hw5.seq2seq | validation loss:\t2.5845\n",
      "2021-04-29 01:01:46 | INFO | hw5.seq2seq | BLEU = 21.16 57.9/29.5/17.0/10.2 (BP = 0.908 ratio = 0.912 hyp_len = 70251 ref_len = 77050)\n",
      "2021-04-29 01:01:46 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint22.pt\n",
      "2021-04-29 01:01:47 | INFO | hw5.seq2seq | end of epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:07:00 | INFO | hw5.seq2seq | training loss: 2.0528\n",
      "2021-04-29 01:07:00 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:07:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 01:07:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 01:07:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:07:43 | INFO | hw5.seq2seq | example source: 我想這項科技的運用讓道格拉斯.諾斯感到驚訝的地方 , 應該就是區塊鏈技術真的辦到了 , 而讓區塊鏈維持安全且易確證的原因就是我們彼此的不信任 。\n",
      "2021-04-29 01:07:43 | INFO | hw5.seq2seq | example hypothesis: and i think what surprised douglas noses , i think , was that blockchain technology really did it , and the reason that blockchains stay safe and clear is that we distrust each other .\n",
      "2021-04-29 01:07:43 | INFO | hw5.seq2seq | example reference: i think what would probably floor douglass north about this use of technology is the fact that the very thing that makes it work , the very thing that keeps the blockchain secure and verified , is our mutual distrust .\n",
      "2021-04-29 01:07:43 | INFO | hw5.seq2seq | validation loss:\t2.5860\n",
      "2021-04-29 01:07:43 | INFO | hw5.seq2seq | BLEU = 20.94 58.3/29.6/17.2/10.3 (BP = 0.891 ratio = 0.897 hyp_len = 69091 ref_len = 77050)\n",
      "2021-04-29 01:07:44 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint23.pt\n",
      "2021-04-29 01:07:44 | INFO | hw5.seq2seq | end of epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:12:58 | INFO | hw5.seq2seq | training loss: 2.0361\n",
      "2021-04-29 01:12:58 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:13:39 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 01:13:39 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 01:13:39 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:13:40 | INFO | hw5.seq2seq | example source: 在那種情況下 , 我們可能會在給法院的信中建議發給緩刑者條列重要訊息的講義 。\n",
      "2021-04-29 01:13:40 | INFO | hw5.seq2seq | example hypothesis: in that situation , we could recommend key messages to the probationer in court advice .\n",
      "2021-04-29 01:13:40 | INFO | hw5.seq2seq | example reference: in that case , our letter to the court might suggest that that probationer get handouts of important information .\n",
      "2021-04-29 01:13:40 | INFO | hw5.seq2seq | validation loss:\t2.5935\n",
      "2021-04-29 01:13:40 | INFO | hw5.seq2seq | BLEU = 21.22 57.2/29.0/16.7/10.0 (BP = 0.924 ratio = 0.927 hyp_len = 71435 ref_len = 77050)\n",
      "2021-04-29 01:13:41 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint24.pt\n",
      "2021-04-29 01:13:41 | INFO | hw5.seq2seq | end of epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:18:54 | INFO | hw5.seq2seq | training loss: 2.0206\n",
      "2021-04-29 01:18:54 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:19:35 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 01:19:35 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 01:19:35 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:19:36 | INFO | hw5.seq2seq | example source: 因此我們就先開始了一個臉書網頁 , 然後一個宣言 , 然後以一個非常簡單的方式 , 從街道開始報導 。\n",
      "2021-04-29 01:19:36 | INFO | hw5.seq2seq | example hypothesis: so we started with a facebook page , and then announcing , and then reporting on the street in a very simple way .\n",
      "2021-04-29 01:19:36 | INFO | hw5.seq2seq | example reference: so we launched a facebook page first , and then a manifesto , and started to cover the streets in a very simple way .\n",
      "2021-04-29 01:19:36 | INFO | hw5.seq2seq | validation loss:\t2.5991\n",
      "2021-04-29 01:19:36 | INFO | hw5.seq2seq | BLEU = 20.95 57.7/29.3/16.8/10.0 (BP = 0.908 ratio = 0.912 hyp_len = 70264 ref_len = 77050)\n",
      "2021-04-29 01:19:37 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint25.pt\n",
      "2021-04-29 01:19:37 | INFO | hw5.seq2seq | end of epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:24:50 | INFO | hw5.seq2seq | training loss: 2.0052\n",
      "2021-04-29 01:24:50 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:25:32 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 01:25:32 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 01:25:32 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:25:33 | INFO | hw5.seq2seq | example source: 你的戒指呢 ?\n",
      "2021-04-29 01:25:33 | INFO | hw5.seq2seq | example hypothesis: what about your ring ?\n",
      "2021-04-29 01:25:33 | INFO | hw5.seq2seq | example reference: do you have a ring as well ?\n",
      "2021-04-29 01:25:33 | INFO | hw5.seq2seq | validation loss:\t2.6062\n",
      "2021-04-29 01:25:33 | INFO | hw5.seq2seq | BLEU = 21.10 56.6/28.4/16.3/9.6 (BP = 0.941 ratio = 0.943 hyp_len = 72650 ref_len = 77050)\n",
      "2021-04-29 01:25:33 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint26.pt\n",
      "2021-04-29 01:25:33 | INFO | hw5.seq2seq | end of epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:30:47 | INFO | hw5.seq2seq | training loss: 1.9911\n",
      "2021-04-29 01:30:47 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:31:29 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 01:31:29 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 01:31:29 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:31:29 | INFO | hw5.seq2seq | example source: 我們無意要搞笑 , 我們也不是打算...不 , 應該說我們本來只打算搞笑\n",
      "2021-04-29 01:31:29 | INFO | hw5.seq2seq | example hypothesis: we're not trying to be funny , we're not trying to no , we're just trying to be funny .\n",
      "2021-04-29 01:31:29 | INFO | hw5.seq2seq | example reference: we weren't trying to be funny , we weren't trying to be well , we were trying to be funny actually , that's not true .\n",
      "2021-04-29 01:31:29 | INFO | hw5.seq2seq | validation loss:\t2.6226\n",
      "2021-04-29 01:31:29 | INFO | hw5.seq2seq | BLEU = 20.98 57.2/28.8/16.6/9.9 (BP = 0.921 ratio = 0.924 hyp_len = 71169 ref_len = 77050)\n",
      "2021-04-29 01:31:30 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint27.pt\n",
      "2021-04-29 01:31:30 | INFO | hw5.seq2seq | end of epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:36:44 | INFO | hw5.seq2seq | training loss: 1.9775\n",
      "2021-04-29 01:36:44 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:37:27 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 01:37:27 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 01:37:27 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:37:27 | INFO | hw5.seq2seq | example source: 你要做的 , 就是把你的問題和以前別人所遇到的問題做比對 , 再利用他們已經想出的辦法來解決 。\n",
      "2021-04-29 01:37:27 | INFO | hw5.seq2seq | example hypothesis: what you have to do is contrast your problems with the problems that people have faced before and harness them to the solutions they've come up with .\n",
      "2021-04-29 01:37:27 | INFO | hw5.seq2seq | example reference: because what you can do is take your problem , and turn it into a problem that someone else has solved , and use their solutions .\n",
      "2021-04-29 01:37:27 | INFO | hw5.seq2seq | validation loss:\t2.6241\n",
      "2021-04-29 01:37:27 | INFO | hw5.seq2seq | BLEU = 21.01 56.8/28.5/16.3/9.7 (BP = 0.934 ratio = 0.936 hyp_len = 72103 ref_len = 77050)\n",
      "2021-04-29 01:37:28 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint28.pt\n",
      "2021-04-29 01:37:28 | INFO | hw5.seq2seq | end of epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:42:42 | INFO | hw5.seq2seq | training loss: 1.9645\n",
      "2021-04-29 01:42:42 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:43:25 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 01:43:25 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 01:43:25 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:43:26 | INFO | hw5.seq2seq | example source: 這就能製造出幻覺來欺騙大腦 , 讓大腦認為想像的瘙癢感已經被解決了 。\n",
      "2021-04-29 01:43:26 | INFO | hw5.seq2seq | example hypothesis: this creates hallucinations in order to trick the brain away from the itchy imagination that the imagination has been resolved .\n",
      "2021-04-29 01:43:26 | INFO | hw5.seq2seq | example reference: that creates an illusion that tricks the brain into thinking the imaginary itch has been satisfied .\n",
      "2021-04-29 01:43:26 | INFO | hw5.seq2seq | validation loss:\t2.6338\n",
      "2021-04-29 01:43:26 | INFO | hw5.seq2seq | BLEU = 20.91 56.9/28.7/16.4/9.8 (BP = 0.923 ratio = 0.926 hyp_len = 71370 ref_len = 77050)\n",
      "2021-04-29 01:43:27 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint29.pt\n",
      "2021-04-29 01:43:27 | INFO | hw5.seq2seq | end of epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:48:45 | INFO | hw5.seq2seq | training loss: 1.9530\n",
      "2021-04-29 01:48:45 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:49:28 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 01:49:28 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 01:49:28 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 01:49:28 | INFO | hw5.seq2seq | example source: 你認為我們必須要延遲多久時間為使這種抑制效應無效而這種效應就是知道教職員會看見你的答案 ?\n",
      "2021-04-29 01:49:28 | INFO | hw5.seq2seq | example hypothesis: how long do you think we have to delay to make this institutional effective , and that effect is knowing that the faculty can see your answers ?\n",
      "2021-04-29 01:49:28 | INFO | hw5.seq2seq | example reference: how long a delay do you think we had to add in order to nullify the inhibitory effect of knowing that faculty would see your answers ?\n",
      "2021-04-29 01:49:28 | INFO | hw5.seq2seq | validation loss:\t2.6409\n",
      "2021-04-29 01:49:28 | INFO | hw5.seq2seq | BLEU = 20.69 56.9/28.5/16.3/9.6 (BP = 0.922 ratio = 0.925 hyp_len = 71296 ref_len = 77050)\n",
      "2021-04-29 01:49:29 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn/checkpoint30.pt\n",
      "2021-04-29 01:49:29 | INFO | hw5.seq2seq | end of epoch 30\n"
     ]
    }
   ],
   "source": [
    "epoch_itr = load_data_iterator(task, \"train\", config.start_epoch, config.max_tokens, config.num_workers)\n",
    "try_load_checkpoint(model, optimizer, name=config.resume)\n",
    "while epoch_itr.next_epoch_idx <= config.max_epoch:\n",
    "    # train for one epoch\n",
    "    train_one_epoch(epoch_itr, model, task, criterion, optimizer, config.accum_steps)\n",
    "    stats = validate_and_save(model, task, criterion, optimizer, epoch=epoch_itr.epoch)\n",
    "    logger.info(\"end of epoch {}\".format(epoch_itr.epoch))    \n",
    "    epoch_itr = load_data_iterator(task, \"train\", epoch_itr.next_epoch_idx, config.max_tokens, config.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P27LlLq96Lns"
   },
   "source": [
    "# Submission 繳交檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "eVI2aYR66Lns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(checkpoint_upper_bound=None, inputs=['./checkpoints/rnn'], num_epoch_checkpoints=5, num_update_checkpoints=None, output='./checkpoints/rnn/avg_last_5_checkpoint.pt')\n",
      "averaging checkpoints:  ['./checkpoints/rnn/checkpoint30.pt', './checkpoints/rnn/checkpoint29.pt', './checkpoints/rnn/checkpoint28.pt', './checkpoints/rnn/checkpoint27.pt', './checkpoints/rnn/checkpoint26.pt']\n",
      "Finished writing averaged checkpoint to ./checkpoints/rnn/avg_last_5_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "# 把幾個 checkpoint 平均起來可以達到 ensemble 的效果\n",
    "checkdir=config.savedir\n",
    "!python3 ./fairseq/scripts/average_checkpoints.py \\\n",
    "--inputs {checkdir} \\\n",
    "--num-epoch-checkpoints 5 \\\n",
    "--output {checkdir}/avg_last_5_checkpoint.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMeE7gqH6Lns"
   },
   "source": [
    "## 確認生成繳交檔案的模型參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "K1ud8qp16Lns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:45:13 | INFO | hw5.seq2seq | loaded checkpoint checkpoints/rnn/avg_last_5_checkpoint.pt: step=unknown loss=2.640942335128784 bleu=20.69289644689053\n",
      "2021-04-29 15:45:13 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:45:53 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n",
      "2021-04-29 15:45:53 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-04-29 15:45:53 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:45:54 | INFO | hw5.seq2seq | example source: 好像大家對人物比較有反應 。\n",
      "2021-04-29 15:45:54 | INFO | hw5.seq2seq | example hypothesis: it's like people are more responsive to the characters .\n",
      "2021-04-29 15:45:54 | INFO | hw5.seq2seq | example reference: somehow , to people , we're slightly better at responding to that sometimes .\n",
      "2021-04-29 15:45:54 | INFO | hw5.seq2seq | validation loss:\t2.5965\n",
      "2021-04-29 15:45:54 | INFO | hw5.seq2seq | BLEU = 21.48 57.5/29.3/17.0/10.1 (BP = 0.926 ratio = 0.929 hyp_len = 71547 ref_len = 77050)\n"
     ]
    }
   ],
   "source": [
    "# checkpoint_last.pt : 最後一次檢驗的檔案\n",
    "# checkpoint_best.pt : 檢驗 BLEU 最高的檔案\n",
    "# avg_last_5_checkpoint.pt:　最5後個檔案平均\n",
    "try_load_checkpoint(model, name=\"avg_last_5_checkpoint.pt\")\n",
    "validate(model, task, criterion, log_to_wandb=False)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHbtXnMy6Lnt"
   },
   "source": [
    "### 下載 monolingual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "11Re6h6K6Lnt"
   },
   "outputs": [],
   "source": [
    "mono_dataset_name = 'mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "07UZYUwd6Lnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/mono\n",
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/ted2020\n",
      "ted_zh_corpus.deduped.gz is exist, skip downloading\n"
     ]
    }
   ],
   "source": [
    "mono_prefix = Path(data_dir).absolute() / mono_dataset_name\n",
    "mono_prefix.mkdir(parents=True, exist_ok=True)\n",
    "print(mono_prefix)\n",
    "print(prefix)\n",
    "urls = (\n",
    "    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214986&authkey=AANUKbGfZx0kM80\"',\n",
    "# # If the above links die, use the following instead. \n",
    "#     \"https://www.csie.ntu.edu.tw/~r09922057/ML2021-hw5/ted_zh_corpus.deduped.gz\",\n",
    "# # If the above links die, use the following instead. \n",
    "#     \"https://mega.nz/#!vMNnDShR!4eHDxzlpzIpdpeQTD-htatU_C7QwcBTwGDaSeBqH534\",\n",
    ")\n",
    "file_names = (\n",
    "    'ted_zh_corpus.deduped.gz',\n",
    ")\n",
    "\n",
    "for u, f in zip(urls, file_names):\n",
    "    path = mono_prefix/f\n",
    "    if not path.exists():\n",
    "        if 'mega' in u:\n",
    "            !megadl {u} --path {path}\n",
    "        else:\n",
    "            !wget {u} -O {path}\n",
    "    else:\n",
    "        print(f'{f} is exist, skip downloading')\n",
    "    if path.suffix == \".tgz\":\n",
    "        !tar -xvf {path} -C {prefix}\n",
    "    elif path.suffix == \".zip\":\n",
    "        !unzip -o {path} -d {prefix}\n",
    "    elif path.suffix == \".gz\":\n",
    "        !gzip -fkd {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwlgSYyP6Lnu"
   },
   "source": [
    "### TODO: 清理資料集\n",
    "\n",
    "1. 將太長、太短的句子移除\n",
    "2. 統一標點符號\n",
    "\n",
    "hint: 可以使用clean_s()來協助"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "rQrEbddv6Lnu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/mono/ted_zh_corpus.deduped\n",
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/mono/ted_zh_corpus.deduped.clean.zh & en exists. skipping clean.\n"
     ]
    }
   ],
   "source": [
    "src_lang = 'zh'\n",
    "tgt_lang = 'en'\n",
    "\n",
    "\n",
    "def strQ2B(ustring):\n",
    "    \"\"\"把字串全形轉半形\"\"\"\n",
    "    # 參考來源:https://ithelp.ithome.com.tw/articles/10233122\n",
    "    ss = []\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # 全形空格直接轉換\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全形字元（除空格）根據關係轉化\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss.append(rstring)\n",
    "    return ''.join(ss)\n",
    "                \n",
    "def clean_s(s, lang):\n",
    "    if lang == 'en':\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "        s = s.replace('-', '') # remove '-'\n",
    "        s = re.sub('([.,;!?()\\\"])', r' \\1 ', s) # keep punctuation\n",
    "    elif lang == 'zh':\n",
    "        s = strQ2B(s) # Q2B\n",
    "        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "        s = s.replace(' ', '')\n",
    "        s = s.replace('—', '')\n",
    "        s = s.replace('“', '\"')\n",
    "        s = s.replace('”', '\"')\n",
    "        s = s.replace('_', '')\n",
    "        s = re.sub('([。,;!?()\\\"~「」])', r' \\1 ', s) # keep punctuation\n",
    "    s = ' '.join(s.strip().split())\n",
    "    return s\n",
    "\n",
    "def len_s(s, lang):\n",
    "    if lang == 'zh':\n",
    "        return len(s)\n",
    "    return len(s.split())\n",
    "\n",
    "def clean_corpus(prefix, l1, l2, ratio=9, max_len=1000, min_len=1):\n",
    "    if Path(f'{prefix}.clean.{l1}').exists() and Path(f'{prefix}.clean.{l2}').exists():\n",
    "        print(f'{prefix}.clean.{l1} & {l2} exists. skipping clean.')\n",
    "        return\n",
    "    with open(f'{prefix}', 'r') as l1_in_f:\n",
    "            with open(f'{prefix}.clean.{l1}', 'w') as l1_out_f:\n",
    "                    for s1 in l1_in_f:\n",
    "                        s1 = s1.strip()\n",
    "                        \n",
    "                        s1 = clean_s(s1, l1)\n",
    "                        \n",
    "                        s1_len = len_s(s1, l1)\n",
    "                        \n",
    "                        if min_len > 0: # remove short sentence\n",
    "                            if s1_len < min_len or s2_len < min_len:\n",
    "                                continue\n",
    "                        if max_len > 0: # remove long sentence\n",
    "                            if s1_len > max_len or s2_len > max_len:\n",
    "                                continue\n",
    "#                         if ratio > 0: # remove by ratio of length\n",
    "#                             if s1_len/s2_len > ratio or s2_len/s1_len > ratio:\n",
    "#                                 continue\n",
    "                        print(s1, file=l1_out_f)\n",
    "                        \n",
    "print(f'{mono_prefix}' + '/ted_zh_corpus.deduped')\n",
    "clean_corpus(f'{mono_prefix}' + '/ted_zh_corpus.deduped', src_lang, tgt_lang, ratio=-1, min_len=-1, max_len=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCT3Mu6N6Lns"
   },
   "source": [
    "## 進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "nrTUUH726Lns"
   },
   "outputs": [],
   "source": [
    "def generate_prediction(model, task, split=\"test\", outfile=\"./prediction.txt\"):    \n",
    "    task.load_dataset(split=split, epoch=1)\n",
    "    itr = load_data_iterator(task, split, 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n",
    "    \n",
    "    idxs = []\n",
    "    hyps = []\n",
    "\n",
    "    model.eval()\n",
    "    progress = tqdm(itr, desc=f\"prediction\")\n",
    "    with torch.no_grad():\n",
    "        for i, sample in enumerate(progress):\n",
    "            # validation loss\n",
    "            sample = utils.move_to_cuda(sample, device=device)\n",
    "\n",
    "            # 進行推論\n",
    "            s, h, r = inference_step(sample, model)\n",
    "            \n",
    "            hyps.extend(h)\n",
    "            idxs.extend(list(sample['id']))\n",
    "            \n",
    "    # 根據 preprocess 時的順序排列\n",
    "    hyps = [x for _,x in sorted(zip(idxs,hyps))]\n",
    "    \n",
    "    with open(outfile, \"w\") as f:\n",
    "        for h in hyps:\n",
    "            f.write(h+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA0Mlp7A6Lnu"
   },
   "source": [
    "### TODO: Subword Units\n",
    "\n",
    "用反向模型的 spm model 將資料切成 subword units\n",
    "\n",
    "hint: spm model 的路徑為 DATA/raw-data/\\[dataset\\]/spm\\[vocab_num\\].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "ZTbdRf366Lnu"
   },
   "outputs": [],
   "source": [
    "with open(mono_prefix/'ted_zh_corpus.deduped.clean.en', 'w') as out_f:\n",
    "    with open(mono_prefix/'ted_zh_corpus.deduped.clean.zh', 'r') as in_f:\n",
    "        for line in in_f:\n",
    "            out_f.write('.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/mono/train.zh exists. skipping spm_encode.\n",
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/mono/train.en exists. skipping spm_encode.\n"
     ]
    }
   ],
   "source": [
    "spm_model = spm.SentencePieceProcessor(model_file=str(prefix/f'spm{vocab_size}.model'))\n",
    "in_tag = {\n",
    "    'train': 'ted_zh_corpus.deduped.clean',\n",
    "}\n",
    "for split in ['train']:\n",
    "    for lang in [src_lang, tgt_lang]:\n",
    "        out_path = mono_prefix/f'{split}.{lang}'\n",
    "        if out_path.exists():\n",
    "            print(f\"{out_path} exists. skipping spm_encode.\")\n",
    "        else:\n",
    "            with open(mono_prefix/f'{split}.{lang}', 'w') as out_f:\n",
    "                with open(mono_prefix/f'{in_tag[split]}.{lang}', 'r') as in_f:\n",
    "                    for line in in_f:\n",
    "                        line = line.strip()\n",
    "                        tok = spm_model.encode(line, out_type=str)\n",
    "                        print(' '.join(tok), file=out_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-f1W92s6Lnu"
   },
   "source": [
    "### Binarize\n",
    "\n",
    "使用fairseq將資料轉為binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "8BsB99AD6Lnu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:46:54 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='DATA/data-bin/mono', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='zh', srcdict='./DATA/data-bin/ted2020/dict.zh.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='./DATA/data-bin/ted2020/dict.zh.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/mono/train', user_dir=None, validpref=None, wandb_project=None, workers=1)\n",
      "2021-04-29 15:46:54 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n",
      "2021-04-29 15:47:35 | INFO | fairseq_cli.preprocess | [zh] /home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/mono/train.zh: 782527 sents, 14416029 tokens, 0.00223% replaced by <unk>\n",
      "2021-04-29 15:47:35 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n",
      "2021-04-29 15:47:44 | INFO | fairseq_cli.preprocess | [en] /home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/mono/train.en: 782527 sents, 1565054 tokens, 0.0% replaced by <unk>\n",
      "2021-04-29 15:47:44 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to DATA/data-bin/mono\n"
     ]
    }
   ],
   "source": [
    "binpath = Path('./DATA/data-bin', mono_dataset_name)\n",
    "src_dict_file = './DATA/data-bin/ted2020/dict.zh.txt'\n",
    "tgt_dict_file = src_dict_file\n",
    "monopref = str(mono_prefix/\"mono.tok\") # whatever filepath you get after applying subword tokenization\n",
    "if binpath.exists():\n",
    "    print(binpath, \"exists, will not overwrite!\")\n",
    "else:\n",
    "    !python3 -m fairseq_cli.preprocess\\\n",
    "        --source-lang 'zh'\\\n",
    "        --target-lang 'en'\\\n",
    "        --trainpref {mono_prefix/'train'}\\\n",
    "        --destdir {binpath}\\\n",
    "        --srcdict {src_dict_file}\\\n",
    "        --tgtdict {tgt_dict_file}\\\n",
    "        --workers 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mtDpIoP6Lnt"
   },
   "source": [
    "## 利用反向模型生成額外資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fptVNhAG6Lnu"
   },
   "source": [
    "### TODO: 生成反向翻譯資料\n",
    "\n",
    "將 binarized data 加入原本的資料夾中並用一個 split_name 取名\n",
    "\n",
    "ex. ./DATA/data-bin/ted2020/\\[split_name\\].zh-en.\\[\"en\", \"zh\"\\].\\[\"bin\", \"idx\"\\]\n",
    "\n",
    "便可以使用 generate_prediction(model, task, split=\"split_name\")來產生翻譯資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "9A_Mw_C16Lnu"
   },
   "outputs": [],
   "source": [
    "# 將 binarized data 加入原本的資料夾中並用一個 split_name 取名\n",
    "# ex. ./DATA/data-bin/ted2020/\\[split_name\\].zh-en.\\[\"en\", \"zh\"\\].\\[\"bin\", \"idx\"\\]\n",
    "!cp ./DATA/data-bin/mono/train.zh-en.zh.bin ./DATA/data-bin/ted2020/mono.zh-en.zh.bin\n",
    "!cp ./DATA/data-bin/mono/train.zh-en.zh.idx ./DATA/data-bin/ted2020/mono.zh-en.zh.idx\n",
    "!cp ./DATA/data-bin/mono/train.zh-en.en.bin ./DATA/data-bin/ted2020/mono.zh-en.en.bin\n",
    "!cp ./DATA/data-bin/mono/train.zh-en.en.idx ./DATA/data-bin/ted2020/mono.zh-en.en.idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 13:54:55 | INFO | fairseq.data.data_utils | loaded 782,527 examples from: ./DATA/data-bin/ted2020/mono.zh-en.zh\n",
      "2021-04-29 13:54:55 | INFO | fairseq.data.data_utils | loaded 782,527 examples from: ./DATA/data-bin/ted2020/mono.zh-en.en\n",
      "2021-04-29 13:54:55 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 mono zh-en 782527 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prediction: 100%|██████████| 3533/3533 [1:19:16<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "generate_prediction( model, task, split='mono', outfile='./prediction_file.en' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvhjVFOE6Lnt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzK4Av4i6Lnt"
   },
   "source": [
    "# Back-translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgtzlPw66Lnt"
   },
   "source": [
    "## 訓練一個反向的翻譯模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbOjvK6b6Lnt"
   },
   "source": [
    "1. 將實驗的參數設定表中(config)的source_lang與target_lang互相交換\n",
    "2. 將實驗的參數設定表中(config)的savedir更改(ex. \"./checkpoints/rnn-back\")\n",
    "3. 訓練一個反向模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2y4_5kth6Lnv"
   },
   "outputs": [],
   "source": [
    "# hint: 用反向模型在 split='mono' 上進行預測，生成 prediction_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9dpu1Zh6Lnv"
   },
   "source": [
    "### TODO: 產生新的dataset\n",
    "\n",
    "1. 將翻譯出來的資料與原先的訓練資料結合\n",
    "2. 使用之前的spm model切出成Subword Units\n",
    "3. 重新使用fairseq將資料轉為binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "qPZn26cg6Lnv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/mono/mono.tok.en exists. skipping spm_encode.\n",
      "2021-04-29 15:47:57 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='DATA/data-bin/synthetic', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='zh', srcdict='./DATA/data-bin/ted2020/dict.en.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='./DATA/data-bin/ted2020/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/mono/mono.tok', user_dir=None, validpref=None, wandb_project=None, workers=1)\n",
      "2021-04-29 15:47:57 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n",
      "2021-04-29 15:48:38 | INFO | fairseq_cli.preprocess | [zh] /home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/mono/mono.tok.zh: 782527 sents, 14416029 tokens, 0.00223% replaced by <unk>\n",
      "2021-04-29 15:48:38 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n",
      "2021-04-29 15:49:29 | INFO | fairseq_cli.preprocess | [en] /home/bill/Desktop/Graduate_course/ML2021/hw5/DATA/rawdata/mono/mono.tok.en: 782527 sents, 17522393 tokens, 0.0% replaced by <unk>\n",
      "2021-04-29 15:49:29 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to DATA/data-bin/synthetic\n"
     ]
    }
   ],
   "source": [
    "# 合併剛剛生成的 prediction_file (.en) 以及中文 mono.zh (.zh)\n",
    "# \n",
    "# hint: 在此用剛剛的 spm model 對 prediction_file 進行切斷詞\n",
    "!cp ./DATA/rawdata/mono/train.zh ./DATA/rawdata/mono/mono.tok.zh\n",
    "\n",
    "spm_model = spm.SentencePieceProcessor(model_file=str(prefix/f'spm{vocab_size}.model'))\n",
    "in_tag = {\n",
    "    'train': 'prediction_file.en',\n",
    "}\n",
    "t_f = 'mono.tok.en'\n",
    "for split in ['train']:\n",
    "    for lang in [tgt_lang]:\n",
    "        out_path = mono_prefix/t_f\n",
    "        if out_path.exists():\n",
    "            print(f\"{out_path} exists. skipping spm_encode.\")\n",
    "        else:\n",
    "            with open(mono_prefix/t_f, 'w') as out_f:\n",
    "                with open('./prediction_file.en', 'r') as in_f:\n",
    "                    for line in in_f:\n",
    "                        line = line.strip()\n",
    "                        tok = spm_model.encode(line, out_type=str)\n",
    "                        print(' '.join(tok), file=out_f)\n",
    "# output: ./DATA/rawdata/mono/mono.tok.en & mono.tok.zh\n",
    "\n",
    "# hint: 在此用 fairseq 把這些檔案再 binarize\n",
    "binpath = Path('./DATA/data-bin/synthetic')\n",
    "src_dict_file = './DATA/data-bin/ted2020/dict.en.txt'\n",
    "tgt_dict_file = src_dict_file\n",
    "\n",
    "if binpath.exists():\n",
    "    print(binpath, \"exists, will not overwrite!\")\n",
    "else:\n",
    "    !python3 -m fairseq_cli.preprocess\\\n",
    "        --source-lang 'zh'\\\n",
    "        --target-lang 'en'\\\n",
    "        --trainpref {mono_prefix/'mono.tok'}\\\n",
    "        --destdir {binpath}\\\n",
    "        --srcdict {src_dict_file}\\\n",
    "        --tgtdict {tgt_dict_file}\\\n",
    "        --workers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Yj1WKoh36Lnv"
   },
   "outputs": [],
   "source": [
    "# 這裡用剛剛準備的檔案合併原先 ted2020 來生成最終 back-translation 的資料\n",
    "!cp -r ./DATA/data-bin/ted2020/ ./DATA/data-bin/ted2020_with_mono/\n",
    "\n",
    "!cp ./DATA/data-bin/synthetic/train.zh-en.zh.bin ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh.bin\n",
    "!cp ./DATA/data-bin/synthetic/train.zh-en.zh.idx ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh.idx\n",
    "!cp ./DATA/data-bin/synthetic/train.zh-en.en.bin ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en.bin\n",
    "!cp ./DATA/data-bin/synthetic/train.zh-en.en.idx ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en.idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tD7nkmBd6Lnv"
   },
   "source": [
    "### TODO: 重新訓練\n",
    "\n",
    "當已經產生新的資料集\n",
    "\n",
    "1. 將實驗的參數設定表(config)中的datadir改為新的資料集(\"./DATA/data-bin/ted2020_with_mono\")\n",
    "2. 將實驗的參數設定表(config)中的source_lang與target_lang設定還原(\"en\", \"zh\")\n",
    "3. 將實驗的參數設定表(config)中的savedir更改(ex. \"./checkpoints/rnn-bt\")\n",
    "4. 重新訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Namespace(\n",
    "    datadir = \"./DATA/data-bin/ted2020_with_mono\",\n",
    "    savedir = \"./checkpoints/rnn-bt\",\n",
    "    source_lang = \"en\",\n",
    "    target_lang = \"zh\",\n",
    "    \n",
    "    # cpu threads when fetching & processing data.\n",
    "    num_workers=1,  \n",
    "    # batch size in terms of tokens. gradient accumulation increases the effective batchsize.\n",
    "    max_tokens=4096,\n",
    "    accum_steps=4,\n",
    "    \n",
    "    # the lr s calculated from Noam lr scheduler. you can tune the maximum lr by this factor.\n",
    "    lr_factor=2.,\n",
    "    lr_warmup=4000,\n",
    "    \n",
    "    # clipping gradient norm helps alleviate gradient exploding\n",
    "    clip_norm=1.0,\n",
    "    \n",
    "    # maximum epochs for training\n",
    "    max_epoch=30,\n",
    "    start_epoch=1,\n",
    "    \n",
    "    # beam size for beam search\n",
    "    beam=5, \n",
    "    # generate sequences of maximum length ax + b, where x is the source length\n",
    "    max_len_a=1.2, \n",
    "    max_len_b=10,\n",
    "    # when decoding, post process sentence by removing sentencepiece symbols.\n",
    "    post_process = \"sentencepiece\",\n",
    "    \n",
    "    # checkpoints\n",
    "    keep_last_epochs=5,\n",
    "    resume=None, # if resume from checkpoint name (under config.savedir)\n",
    "    \n",
    "    # logging\n",
    "    use_wandb=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=\"INFO\", # \"DEBUG\" \"WARNING\" \"ERROR\"\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "proj = \"hw5.seq2seq\"\n",
    "logger = logging.getLogger(proj)\n",
    "if config.use_wandb:\n",
    "    import wandb\n",
    "    wandb.init(project=proj, name=Path(config.savedir).stem, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:49:52 | INFO | fairseq.tasks.translation | [en] dictionary: 8000 types\n",
      "2021-04-29 15:49:52 | INFO | fairseq.tasks.translation | [zh] dictionary: 8000 types\n"
     ]
    }
   ],
   "source": [
    "from fairseq.tasks.translation import TranslationConfig, TranslationTask\n",
    "\n",
    "## setup task\n",
    "task_cfg = TranslationConfig(\n",
    "    data=config.datadir,\n",
    "    source_lang=config.source_lang,\n",
    "    target_lang=config.target_lang,\n",
    "    train_subset=\"train\",\n",
    "    required_seq_len_multiple=8,\n",
    "    dataset_impl=\"mmap\",\n",
    "    upsample_primary=1,\n",
    ")\n",
    "task = TranslationTask.setup_task(task_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:49:55 | INFO | hw5.seq2seq | loading data for epoch 1\n",
      "2021-04-29 15:49:55 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020_with_mono/train.zh-en.en\n",
      "2021-04-29 15:49:55 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020_with_mono/train.zh-en.zh\n",
      "2021-04-29 15:49:55 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020_with_mono train en-zh 390041 examples\n",
      "2021-04-29 15:49:55 | INFO | fairseq.data.data_utils | loaded 782,527 examples from: ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en\n",
      "2021-04-29 15:49:55 | INFO | fairseq.data.data_utils | loaded 782,527 examples from: ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh\n",
      "2021-04-29 15:49:55 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020_with_mono train1 en-zh 782527 examples\n",
      "2021-04-29 15:49:55 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020_with_mono/valid.zh-en.en\n",
      "2021-04-29 15:49:55 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020_with_mono/valid.zh-en.zh\n",
      "2021-04-29 15:49:55 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020_with_mono valid en-zh 3939 examples\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"loading data for epoch 1\")\n",
    "task.load_dataset(split=\"train\", epoch=1, combine=True) # combine if you have back-translation data.\n",
    "task.load_dataset(split=\"valid\", epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device=device)\n",
    "criterion = criterion.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 15:50:00 | WARNING | fairseq.tasks.fairseq_task | 1 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[326674]\n",
      "2021-04-29 15:50:00 | INFO | hw5.seq2seq | no checkpoints found at checkpoints/rnn-bt/checkpoint_last.pt!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "train epoch 1:   0%|          | 0/1894 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 16:02:01 | INFO | hw5.seq2seq | training loss: 5.1597\n",
      "2021-04-29 16:02:01 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 16:02:37 | INFO | hw5.seq2seq | example source: thank you . thank you .\n",
      "2021-04-29 16:02:37 | INFO | hw5.seq2seq | example hypothesis: 謝謝 。 謝謝 。\n",
      "2021-04-29 16:02:37 | INFO | hw5.seq2seq | example reference: 謝謝 。 謝謝 。\n",
      "2021-04-29 16:02:37 | INFO | hw5.seq2seq | validation loss:\t3.8400\n",
      "2021-04-29 16:02:37 | INFO | hw5.seq2seq | BLEU = 20.28 53.7/27.7/15.0/8.7 (BP = 0.967 ratio = 0.968 hyp_len = 108212 ref_len = 111811)\n",
      "2021-04-29 16:02:37 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint1.pt\n",
      "2021-04-29 16:02:37 | INFO | hw5.seq2seq | end of epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 16:14:42 | INFO | hw5.seq2seq | training loss: 3.3194\n",
      "2021-04-29 16:14:42 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 16:15:18 | INFO | hw5.seq2seq | example source: but you know what happened to my country .\n",
      "2021-04-29 16:15:18 | INFO | hw5.seq2seq | example hypothesis: 但是你知道我國家發生了什麼事 。\n",
      "2021-04-29 16:15:18 | INFO | hw5.seq2seq | example reference: 但是你們都知道我的國家發生了什麼 。\n",
      "2021-04-29 16:15:18 | INFO | hw5.seq2seq | validation loss:\t3.4332\n",
      "2021-04-29 16:15:18 | INFO | hw5.seq2seq | BLEU = 23.55 56.8/31.1/17.8/10.7 (BP = 0.977 ratio = 0.978 hyp_len = 109300 ref_len = 111811)\n",
      "2021-04-29 16:15:18 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint2.pt\n",
      "2021-04-29 16:15:19 | INFO | hw5.seq2seq | end of epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 16:27:24 | INFO | hw5.seq2seq | training loss: 3.0446\n",
      "2021-04-29 16:27:24 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 16:28:01 | INFO | hw5.seq2seq | example source: if we look at the selectivity of responses in the cortex of the monkey , we see that the monkey has actually changed the filter characteristics which represents input from the skin of the fingertips that are engaged .\n",
      "2021-04-29 16:28:01 | INFO | hw5.seq2seq | example hypothesis: 如果我們看看猴子皮層的選擇性 , 我們會發現猴子其實已經改變過濾器的特徵 , 可以從手指的皮膚中輸入 。\n",
      "2021-04-29 16:28:01 | INFO | hw5.seq2seq | example reference: 假如我們看到猴子的大腦皮層中 , 對應這些動作的區域有反應 , 我們可以看到猴子正利用從指尖皮膚執行動作時的回饋訊號 , 來調整 , 建立適當的過濾器 。\n",
      "2021-04-29 16:28:01 | INFO | hw5.seq2seq | validation loss:\t3.2194\n",
      "2021-04-29 16:28:01 | INFO | hw5.seq2seq | BLEU = 25.50 57.9/32.8/19.5/12.1 (BP = 0.985 ratio = 0.985 hyp_len = 110178 ref_len = 111811)\n",
      "2021-04-29 16:28:01 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint3.pt\n",
      "2021-04-29 16:28:02 | INFO | hw5.seq2seq | end of epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 16:40:08 | INFO | hw5.seq2seq | training loss: 2.8821\n",
      "2021-04-29 16:40:08 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 16:40:42 | INFO | hw5.seq2seq | example source: and then he said , \" why would they vote for him ? \"\n",
      "2021-04-29 16:40:42 | INFO | hw5.seq2seq | example hypothesis: 然後他說: 「 為什麼他們會投票給他 ? 」\n",
      "2021-04-29 16:40:42 | INFO | hw5.seq2seq | example reference: 接著他說: 「 他們為何投給他 ? 」\n",
      "2021-04-29 16:40:42 | INFO | hw5.seq2seq | validation loss:\t3.1373\n",
      "2021-04-29 16:40:42 | INFO | hw5.seq2seq | BLEU = 26.01 59.7/34.5/20.8/13.0 (BP = 0.952 ratio = 0.953 hyp_len = 106542 ref_len = 111811)\n",
      "2021-04-29 16:40:43 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint4.pt\n",
      "2021-04-29 16:40:44 | INFO | hw5.seq2seq | end of epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 16:52:49 | INFO | hw5.seq2seq | training loss: 2.7851\n",
      "2021-04-29 16:52:49 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 16:53:26 | INFO | hw5.seq2seq | example source: lp: yeah , absolutely .\n",
      "2021-04-29 16:53:26 | INFO | hw5.seq2seq | example hypothesis: 賴瑞.佩吉:是的 , 絕對是 。\n",
      "2021-04-29 16:53:26 | INFO | hw5.seq2seq | example reference: 賴瑞.佩吉:是的 , 毫無疑問 。\n",
      "2021-04-29 16:53:26 | INFO | hw5.seq2seq | validation loss:\t3.0751\n",
      "2021-04-29 16:53:26 | INFO | hw5.seq2seq | BLEU = 26.99 58.9/34.1/20.8/13.2 (BP = 0.989 ratio = 0.989 hyp_len = 110636 ref_len = 111811)\n",
      "2021-04-29 16:53:27 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint5.pt\n",
      "2021-04-29 16:53:27 | INFO | hw5.seq2seq | end of epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 17:05:34 | INFO | hw5.seq2seq | training loss: 2.7152\n",
      "2021-04-29 17:05:34 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 17:06:09 | INFO | hw5.seq2seq | example source: then , and only then , hope will come .\n",
      "2021-04-29 17:06:09 | INFO | hw5.seq2seq | example hypothesis: 然後 , 只有這樣 , 希望才會來 。\n",
      "2021-04-29 17:06:09 | INFO | hw5.seq2seq | example reference: 這樣 , 也唯有這麼做 , 希望才會到來 。\n",
      "2021-04-29 17:06:09 | INFO | hw5.seq2seq | validation loss:\t3.0462\n",
      "2021-04-29 17:06:09 | INFO | hw5.seq2seq | BLEU = 27.69 59.5/34.8/21.4/13.8 (BP = 0.990 ratio = 0.990 hyp_len = 110680 ref_len = 111811)\n",
      "2021-04-29 17:06:10 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint6.pt\n",
      "2021-04-29 17:06:11 | INFO | hw5.seq2seq | end of epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 17:18:18 | INFO | hw5.seq2seq | training loss: 2.6612\n",
      "2021-04-29 17:18:18 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 17:18:54 | INFO | hw5.seq2seq | example source: you're avoiding outside areas , or you're closing your window .\n",
      "2021-04-29 17:18:54 | INFO | hw5.seq2seq | example hypothesis: 你避開外面的區域 , 或是關閉你的窗戶 。\n",
      "2021-04-29 17:18:54 | INFO | hw5.seq2seq | example reference: 你會避開外圍的區域 , 或是你會把窗戶關上 。\n",
      "2021-04-29 17:18:54 | INFO | hw5.seq2seq | validation loss:\t3.0071\n",
      "2021-04-29 17:18:54 | INFO | hw5.seq2seq | BLEU = 27.77 59.4/34.7/21.4/13.8 (BP = 0.995 ratio = 0.995 hyp_len = 111208 ref_len = 111811)\n",
      "2021-04-29 17:18:55 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint7.pt\n",
      "2021-04-29 17:18:55 | INFO | hw5.seq2seq | end of epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 17:31:00 | INFO | hw5.seq2seq | training loss: 2.6172\n",
      "2021-04-29 17:31:00 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 17:31:37 | INFO | hw5.seq2seq | example source: and we're going to walk in .\n",
      "2021-04-29 17:31:37 | INFO | hw5.seq2seq | example hypothesis: 然後我們要走進去 。\n",
      "2021-04-29 17:31:37 | INFO | hw5.seq2seq | example reference: 我們現在要走進去 。\n",
      "2021-04-29 17:31:37 | INFO | hw5.seq2seq | validation loss:\t2.9858\n",
      "2021-04-29 17:31:37 | INFO | hw5.seq2seq | BLEU = 27.99 59.3/34.8/21.5/13.8 (BP = 1.000 ratio = 1.001 hyp_len = 111890 ref_len = 111811)\n",
      "2021-04-29 17:31:37 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint8.pt\n",
      "2021-04-29 17:31:38 | INFO | hw5.seq2seq | end of epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 17:43:43 | INFO | hw5.seq2seq | training loss: 2.5791\n",
      "2021-04-29 17:43:43 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 17:44:17 | INFO | hw5.seq2seq | example source: chris anderson: so help me out on one thing , because there've been a few augmented reality demos shown over the last year or so out there .\n",
      "2021-04-29 17:44:17 | INFO | hw5.seq2seq | example hypothesis: 克里斯·安德森:幫我做一件事 , 因為在過去一年左右 , 實境秀已經出現了幾個擴增實境示範 。\n",
      "2021-04-29 17:44:17 | INFO | hw5.seq2seq | example reference: 克里斯·安德森:請解答我的一個小疑惑 , 過去一年甚至更久之前就出現過許多擴增實境的展示 ,\n",
      "2021-04-29 17:44:17 | INFO | hw5.seq2seq | validation loss:\t2.9823\n",
      "2021-04-29 17:44:17 | INFO | hw5.seq2seq | BLEU = 27.82 60.5/35.6/22.1/14.4 (BP = 0.967 ratio = 0.968 hyp_len = 108181 ref_len = 111811)\n",
      "2021-04-29 17:44:18 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint9.pt\n",
      "2021-04-29 17:44:18 | INFO | hw5.seq2seq | end of epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 17:56:23 | INFO | hw5.seq2seq | training loss: 2.5470\n",
      "2021-04-29 17:56:23 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 17:56:59 | INFO | hw5.seq2seq | example source: just yesterday , i was attacked by a guy who claimed that i was filming him .\n",
      "2021-04-29 17:56:59 | INFO | hw5.seq2seq | example hypothesis: 就在昨天 , 我被一個人攻擊 , 他宣稱我在拍攝他 。\n",
      "2021-04-29 17:56:59 | INFO | hw5.seq2seq | example reference: 就在昨天 , 我被一個傢伙攻擊了 , 他聲稱我在拍攝他 。\n",
      "2021-04-29 17:56:59 | INFO | hw5.seq2seq | validation loss:\t2.9650\n",
      "2021-04-29 17:56:59 | INFO | hw5.seq2seq | BLEU = 28.40 59.9/35.4/22.0/14.3 (BP = 0.994 ratio = 0.994 hyp_len = 111094 ref_len = 111811)\n",
      "2021-04-29 17:57:00 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint10.pt\n",
      "2021-04-29 17:57:01 | INFO | hw5.seq2seq | end of epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 18:09:06 | INFO | hw5.seq2seq | training loss: 2.5183\n",
      "2021-04-29 18:09:06 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 18:09:42 | INFO | hw5.seq2seq | example source: i mean , i wish i had a softer voice maybe , but now i walk in love and i try to live that way every day .\n",
      "2021-04-29 18:09:42 | INFO | hw5.seq2seq | example hypothesis: 我的意思是 , 我希望我有發言權 , 但現在我走進愛河 , 我每天都這樣生活 。\n",
      "2021-04-29 18:09:42 | INFO | hw5.seq2seq | example reference: 不過我希望能有更溫柔的聲音 , 但是我現在被愛環繞著 , 我希望能一直這樣下去 。\n",
      "2021-04-29 18:09:42 | INFO | hw5.seq2seq | validation loss:\t2.9625\n",
      "2021-04-29 18:09:42 | INFO | hw5.seq2seq | BLEU = 28.48 60.1/35.7/22.3/14.6 (BP = 0.986 ratio = 0.986 hyp_len = 110246 ref_len = 111811)\n",
      "2021-04-29 18:09:42 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint11.pt\n",
      "2021-04-29 18:09:43 | INFO | hw5.seq2seq | end of epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 18:21:48 | INFO | hw5.seq2seq | training loss: 2.4929\n",
      "2021-04-29 18:21:48 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 18:22:24 | INFO | hw5.seq2seq | example source: it contains an army of me lifesize sculptures as you can see behind me , they're here they are my life , really .\n",
      "2021-04-29 18:22:24 | INFO | hw5.seq2seq | example hypothesis: 它包含了一支我大大的雕塑品 , 就像你們在我身後看到的 , 它們就是我的生命 。\n",
      "2021-04-29 18:22:24 | INFO | hw5.seq2seq | example reference: 展覽內容包含了軍隊陣容的我你看到在我後面這些真人大小的雕塑 , 它們全都在這裡都是我的生命 , 真的 。\n",
      "2021-04-29 18:22:24 | INFO | hw5.seq2seq | validation loss:\t2.9520\n",
      "2021-04-29 18:22:24 | INFO | hw5.seq2seq | BLEU = 28.74 60.1/35.7/22.4/14.7 (BP = 0.992 ratio = 0.992 hyp_len = 110908 ref_len = 111811)\n",
      "2021-04-29 18:22:24 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint12.pt\n",
      "2021-04-29 18:22:25 | INFO | hw5.seq2seq | end of epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 18:34:31 | INFO | hw5.seq2seq | training loss: 2.4705\n",
      "2021-04-29 18:34:31 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 18:35:07 | INFO | hw5.seq2seq | example source: up above my head up above my head i hear singin' in the air singin' in the air .\n",
      "2021-04-29 18:35:07 | INFO | hw5.seq2seq | example hypothesis: 在我的頭頂上 , 在我的頭頂上 , 我聽見空氣中的歌聲 。\n",
      "2021-04-29 18:35:07 | INFO | hw5.seq2seq | example reference: 在我的頭頂上 , 在我的頭頂上 , 我聽見空氣中的歌聲 , 空氣中的歌聲 。\n",
      "2021-04-29 18:35:07 | INFO | hw5.seq2seq | validation loss:\t2.9445\n",
      "2021-04-29 18:35:07 | INFO | hw5.seq2seq | BLEU = 28.56 59.7/35.4/22.1/14.5 (BP = 0.995 ratio = 0.995 hyp_len = 111241 ref_len = 111811)\n",
      "2021-04-29 18:35:08 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint13.pt\n",
      "2021-04-29 18:35:08 | INFO | hw5.seq2seq | end of epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 18:47:14 | INFO | hw5.seq2seq | training loss: 2.4498\n",
      "2021-04-29 18:47:14 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 18:47:50 | INFO | hw5.seq2seq | example source: the old man crooked his finger as though he were firing a gun , and then he made laser sounds .\n",
      "2021-04-29 18:47:50 | INFO | hw5.seq2seq | example hypothesis: 老男人用手握住手指 , 彷彿他正在開槍 , 接著他發出雷射的聲音 。\n",
      "2021-04-29 18:47:50 | INFO | hw5.seq2seq | example reference: 這個做了一個開槍的手勢 , 並且他發出激光槍的聲音 ,\n",
      "2021-04-29 18:47:50 | INFO | hw5.seq2seq | validation loss:\t2.9491\n",
      "2021-04-29 18:47:50 | INFO | hw5.seq2seq | BLEU = 28.75 59.8/35.4/22.2/14.6 (BP = 1.000 ratio = 1.000 hyp_len = 111790 ref_len = 111811)\n",
      "2021-04-29 18:47:51 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint14.pt\n",
      "2021-04-29 18:47:51 | INFO | hw5.seq2seq | end of epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 18:59:55 | INFO | hw5.seq2seq | training loss: 2.4309\n",
      "2021-04-29 18:59:55 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 19:00:31 | INFO | hw5.seq2seq | example source: one was growing out the back and it attached to the psoas muscle , which is a big muscle in the back that i'd never heard of , but all of a sudden i cared about it .\n",
      "2021-04-29 19:00:31 | INFO | hw5.seq2seq | example hypothesis: 一個長出背部 , 附著在波濤洶湧的肌肉上 , 背後有一塊我從未聽過的大肌肉 , 但突然間 , 我就很在意了 。\n",
      "2021-04-29 19:00:31 | INFO | hw5.seq2seq | example reference: 一個長在背面 , 黏在比目魚肌上這是一個我未曾聽聞的背部大肌肉但是突然間我在意起它來\n",
      "2021-04-29 19:00:31 | INFO | hw5.seq2seq | validation loss:\t2.9391\n",
      "2021-04-29 19:00:31 | INFO | hw5.seq2seq | BLEU = 28.93 60.1/35.9/22.6/14.9 (BP = 0.991 ratio = 0.991 hyp_len = 110777 ref_len = 111811)\n",
      "2021-04-29 19:00:32 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint15.pt\n",
      "2021-04-29 19:00:33 | INFO | hw5.seq2seq | end of epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 19:12:38 | INFO | hw5.seq2seq | training loss: 2.4139\n",
      "2021-04-29 19:12:38 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 19:13:13 | INFO | hw5.seq2seq | example source: and we knew that we were losing co2 .\n",
      "2021-04-29 19:13:13 | INFO | hw5.seq2seq | example hypothesis: 我們知道我們正在失去二氧化碳 。\n",
      "2021-04-29 19:13:13 | INFO | hw5.seq2seq | example reference: 而且我們也知道 , 我們在失去二氧化碳 。\n",
      "2021-04-29 19:13:13 | INFO | hw5.seq2seq | validation loss:\t2.9370\n",
      "2021-04-29 19:13:13 | INFO | hw5.seq2seq | BLEU = 28.93 60.2/35.9/22.6/14.9 (BP = 0.990 ratio = 0.990 hyp_len = 110683 ref_len = 111811)\n",
      "2021-04-29 19:13:14 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint16.pt\n",
      "2021-04-29 19:13:15 | INFO | hw5.seq2seq | end of epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 19:25:20 | INFO | hw5.seq2seq | training loss: 2.3975\n",
      "2021-04-29 19:25:20 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 19:25:56 | INFO | hw5.seq2seq | example source: so dina , this is amazing .\n",
      "2021-04-29 19:25:56 | INFO | hw5.seq2seq | example hypothesis: 迪娜 , 這很了不起 。\n",
      "2021-04-29 19:25:56 | INFO | hw5.seq2seq | example reference: 迪娜 , 這太棒了 。\n",
      "2021-04-29 19:25:56 | INFO | hw5.seq2seq | validation loss:\t2.9383\n",
      "2021-04-29 19:25:56 | INFO | hw5.seq2seq | BLEU = 28.84 59.8/35.7/22.4/14.7 (BP = 0.996 ratio = 0.996 hyp_len = 111325 ref_len = 111811)\n",
      "2021-04-29 19:25:57 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint17.pt\n",
      "2021-04-29 19:25:57 | INFO | hw5.seq2seq | end of epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 19:38:03 | INFO | hw5.seq2seq | training loss: 2.3822\n",
      "2021-04-29 19:38:03 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 19:38:38 | INFO | hw5.seq2seq | example source: and they will live for 15 or 20 years , continuing to lay eggs using the sperm from that original mating .\n",
      "2021-04-29 19:38:38 | INFO | hw5.seq2seq | example hypothesis: 它們會活十五或二十年 , 持續產卵 , 使用原本交配的精子 。\n",
      "2021-04-29 19:38:38 | INFO | hw5.seq2seq | example reference: 她們會活15到20年 , 並且利用與公蟻交配時留下的精液 , 每年持續不斷地產卵 。\n",
      "2021-04-29 19:38:38 | INFO | hw5.seq2seq | validation loss:\t2.9335\n",
      "2021-04-29 19:38:38 | INFO | hw5.seq2seq | BLEU = 28.81 60.0/35.8/22.5/14.8 (BP = 0.990 ratio = 0.990 hyp_len = 110729 ref_len = 111811)\n",
      "2021-04-29 19:38:39 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint18.pt\n",
      "2021-04-29 19:38:39 | INFO | hw5.seq2seq | end of epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 19:50:45 | INFO | hw5.seq2seq | training loss: 2.3692\n",
      "2021-04-29 19:50:45 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 19:51:21 | INFO | hw5.seq2seq | example source: we want to have a situation where algorithms are constantly scouring every single tweet and bringing the most interesting ones to the top so that humans can bring their judgment to whether we should take action or not , based on our terms of service .\n",
      "2021-04-29 19:51:21 | INFO | hw5.seq2seq | example hypothesis: 我們希望有一個情況 , 讓演算法不斷搜索每一則推文 , 並把最有意思的推文帶到最頂端 , 這麼一來 , 人類就能把判斷力帶到我們是否應該採取行動 , 根據我們的服務方式 。\n",
      "2021-04-29 19:51:21 | INFO | hw5.seq2seq | example reference: 我們想要做到讓演算法能不斷搜索每一則推文 , 把最值得注意的推文置頂 , 這麼一來 , 人類可以去判斷我們是否要採取行動 , 依據服務條款來決定 。\n",
      "2021-04-29 19:51:21 | INFO | hw5.seq2seq | validation loss:\t2.9386\n",
      "2021-04-29 19:51:21 | INFO | hw5.seq2seq | BLEU = 29.02 60.0/35.8/22.5/14.8 (BP = 0.997 ratio = 0.997 hyp_len = 111432 ref_len = 111811)\n",
      "2021-04-29 19:51:22 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint19.pt\n",
      "2021-04-29 19:51:23 | INFO | hw5.seq2seq | end of epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 20:03:28 | INFO | hw5.seq2seq | training loss: 2.3560\n",
      "2021-04-29 20:03:28 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 20:04:03 | INFO | hw5.seq2seq | example source: has the computer already matched or even surpassed human capabilities ?\n",
      "2021-04-29 20:04:03 | INFO | hw5.seq2seq | example hypothesis: 電腦已經配合或甚至超越人類能力了嗎 ?\n",
      "2021-04-29 20:04:03 | INFO | hw5.seq2seq | example reference: 就是來告訴各位電腦已經趕上甚至超越人類了嗎 ?\n",
      "2021-04-29 20:04:03 | INFO | hw5.seq2seq | validation loss:\t2.9361\n",
      "2021-04-29 20:04:03 | INFO | hw5.seq2seq | BLEU = 29.07 60.3/36.0/22.8/15.1 (BP = 0.987 ratio = 0.987 hyp_len = 110396 ref_len = 111811)\n",
      "2021-04-29 20:04:04 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint20.pt\n",
      "2021-04-29 20:04:05 | INFO | hw5.seq2seq | end of epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 20:16:09 | INFO | hw5.seq2seq | training loss: 2.3442\n",
      "2021-04-29 20:16:09 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 20:16:46 | INFO | hw5.seq2seq | example source: so i don't have a problem with developers making money .\n",
      "2021-04-29 20:16:46 | INFO | hw5.seq2seq | example hypothesis: 所以我沒有開發商賺錢的問題 。\n",
      "2021-04-29 20:16:46 | INFO | hw5.seq2seq | example reference: 所以我不反對開發商賺錢 ,\n",
      "2021-04-29 20:16:46 | INFO | hw5.seq2seq | validation loss:\t2.9418\n",
      "2021-04-29 20:16:46 | INFO | hw5.seq2seq | BLEU = 29.08 59.8/35.6/22.5/14.9 (BP = 1.000 ratio = 1.003 hyp_len = 112107 ref_len = 111811)\n",
      "2021-04-29 20:16:46 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint21.pt\n",
      "2021-04-29 20:16:47 | INFO | hw5.seq2seq | end of epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 20:28:51 | INFO | hw5.seq2seq | training loss: 2.3326\n",
      "2021-04-29 20:28:51 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 20:29:27 | INFO | hw5.seq2seq | example source: so now i want to take you to the moment of when you're an entrepreneur , and you've started a new company , there's the , here's all the stuff we do beforehand , and then the service launches . what happens ?\n",
      "2021-04-29 20:29:27 | INFO | hw5.seq2seq | example hypothesis: 所以現在我想帶你們到當你們成為創業家的那一刻 , 你們成立了一間新公司 , 裡面有 , 這裡有我們在之前所做的所有東西 , 然後服務就會啟動 。 會發生什麼事 ?\n",
      "2021-04-29 20:29:27 | INFO | hw5.seq2seq | example reference: 現在 , 我要提出一個問題請各位想想如果你是企業家 , 你剛創立了一間新公司然後呢 , 我們做了這些事前準備然後開始營運了 。 接下來呢 ?\n",
      "2021-04-29 20:29:27 | INFO | hw5.seq2seq | validation loss:\t2.9380\n",
      "2021-04-29 20:29:27 | INFO | hw5.seq2seq | BLEU = 29.05 59.7/35.5/22.5/15.0 (BP = 1.000 ratio = 1.002 hyp_len = 111995 ref_len = 111811)\n",
      "2021-04-29 20:29:28 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint22.pt\n",
      "2021-04-29 20:29:28 | INFO | hw5.seq2seq | end of epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 20:41:32 | INFO | hw5.seq2seq | training loss: 2.3213\n",
      "2021-04-29 20:41:32 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 20:42:08 | INFO | hw5.seq2seq | example source: during one visit i observed , trina chatted with a young soontobe mom while she took her blood pressure .\n",
      "2021-04-29 20:42:08 | INFO | hw5.seq2seq | example hypothesis: 在一次參觀時 , 崔伊娜和一位年輕的獨自媽媽聊天 , 她接受了血壓 。\n",
      "2021-04-29 20:42:08 | INFO | hw5.seq2seq | example reference: 在一次參訪時我觀察到 , 崔伊娜和一位年輕的準媽媽聊天 , 一面量著她的血壓 。\n",
      "2021-04-29 20:42:08 | INFO | hw5.seq2seq | validation loss:\t2.9383\n",
      "2021-04-29 20:42:08 | INFO | hw5.seq2seq | BLEU = 29.08 60.0/35.9/22.7/15.1 (BP = 0.993 ratio = 0.993 hyp_len = 110988 ref_len = 111811)\n",
      "2021-04-29 20:42:09 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint23.pt\n",
      "2021-04-29 20:42:09 | INFO | hw5.seq2seq | end of epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 20:54:13 | INFO | hw5.seq2seq | training loss: 2.3114\n",
      "2021-04-29 20:54:13 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 20:54:49 | INFO | hw5.seq2seq | example source: i walked back the two miles from my neurologist's office to my house , my legs wrapped in this strange , almost electric kind of pain .\n",
      "2021-04-29 20:54:49 | INFO | hw5.seq2seq | example hypothesis: 我走回從我的神經科醫生辦公室的兩哩路回到我家 , 我的雙腿包裹著這奇怪的 , 幾乎是電動的感覺 。\n",
      "2021-04-29 20:54:49 | INFO | hw5.seq2seq | example reference: 我走了兩英里 , 從我的神經科醫師的診所回到家裡 , 我的腿感覺被包在一種奇怪的像是被電到的痛苦 。\n",
      "2021-04-29 20:54:49 | INFO | hw5.seq2seq | validation loss:\t2.9383\n",
      "2021-04-29 20:54:49 | INFO | hw5.seq2seq | BLEU = 29.27 60.2/36.1/23.0/15.3 (BP = 0.989 ratio = 0.989 hyp_len = 110633 ref_len = 111811)\n",
      "2021-04-29 20:54:50 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint24.pt\n",
      "2021-04-29 20:54:50 | INFO | hw5.seq2seq | end of epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 21:06:55 | INFO | hw5.seq2seq | training loss: 2.3018\n",
      "2021-04-29 21:06:55 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 21:07:31 | INFO | hw5.seq2seq | example source: why would they cooperate ?\n",
      "2021-04-29 21:07:31 | INFO | hw5.seq2seq | example hypothesis: 他們為什麼要合作 ?\n",
      "2021-04-29 21:07:31 | INFO | hw5.seq2seq | example reference: 那他們為什麼要合作 ?\n",
      "2021-04-29 21:07:31 | INFO | hw5.seq2seq | validation loss:\t2.9370\n",
      "2021-04-29 21:07:31 | INFO | hw5.seq2seq | BLEU = 29.03 60.0/35.9/22.7/15.1 (BP = 0.991 ratio = 0.991 hyp_len = 110754 ref_len = 111811)\n",
      "2021-04-29 21:07:32 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint25.pt\n",
      "2021-04-29 21:07:32 | INFO | hw5.seq2seq | end of epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 21:19:37 | INFO | hw5.seq2seq | training loss: 2.2927\n",
      "2021-04-29 21:19:37 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 21:20:12 | INFO | hw5.seq2seq | example source: we need clever lowkey mechanization that avoids the problems of the largescale mechanization that we've had .\n",
      "2021-04-29 21:20:12 | INFO | hw5.seq2seq | example hypothesis: 我們需要先進的低調機制 , 來避免我們曾有過的大規模機械化的問題 。\n",
      "2021-04-29 21:20:12 | INFO | hw5.seq2seq | example reference: 我們需要機械的幫助 , 但我們不要大規模機械耕種所會帶來的問題 ,\n",
      "2021-04-29 21:20:12 | INFO | hw5.seq2seq | validation loss:\t2.9354\n",
      "2021-04-29 21:20:12 | INFO | hw5.seq2seq | BLEU = 29.16 60.3/36.1/22.9/15.3 (BP = 0.987 ratio = 0.987 hyp_len = 110377 ref_len = 111811)\n",
      "2021-04-29 21:20:13 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint26.pt\n",
      "2021-04-29 21:20:13 | INFO | hw5.seq2seq | end of epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 21:32:19 | INFO | hw5.seq2seq | training loss: 2.2841\n",
      "2021-04-29 21:32:19 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 21:32:54 | INFO | hw5.seq2seq | example source: sighted astronomers depend on this kind of plot in order to interpret how this light intensity changes over time .\n",
      "2021-04-29 21:32:54 | INFO | hw5.seq2seq | example hypothesis: 明眼的天文學家要仰賴這種情節 , 才能詮釋這種光的強度如何隨著時間而改變 。\n",
      "2021-04-29 21:32:54 | INFO | hw5.seq2seq | example reference: 明眼的天文學家倚賴這類的圖來判讀隨時間變化的光強度 。\n",
      "2021-04-29 21:32:54 | INFO | hw5.seq2seq | validation loss:\t2.9398\n",
      "2021-04-29 21:32:54 | INFO | hw5.seq2seq | BLEU = 29.33 60.5/36.3/23.1/15.5 (BP = 0.985 ratio = 0.985 hyp_len = 110183 ref_len = 111811)\n",
      "2021-04-29 21:32:54 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint27.pt\n",
      "2021-04-29 21:32:55 | INFO | hw5.seq2seq | end of epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 21:45:00 | INFO | hw5.seq2seq | training loss: 2.2759\n",
      "2021-04-29 21:45:00 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 21:45:35 | INFO | hw5.seq2seq | example source: the second page is simple: what might be the benefits of an attempt or a partial success ?\n",
      "2021-04-29 21:45:35 | INFO | hw5.seq2seq | example hypothesis: 第二頁很簡單:嘗試或部份成功會有什麼好處 ?\n",
      "2021-04-29 21:45:35 | INFO | hw5.seq2seq | example reference: 第二頁很簡單 , 如果去嘗試或是達成部分成功會有什麼益處 ?\n",
      "2021-04-29 21:45:35 | INFO | hw5.seq2seq | validation loss:\t2.9340\n",
      "2021-04-29 21:45:35 | INFO | hw5.seq2seq | BLEU = 29.06 60.6/36.4/23.1/15.4 (BP = 0.977 ratio = 0.977 hyp_len = 109251 ref_len = 111811)\n",
      "2021-04-29 21:45:36 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint28.pt\n",
      "2021-04-29 21:45:36 | INFO | hw5.seq2seq | end of epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 21:59:39 | INFO | hw5.seq2seq | training loss: 2.2680\n",
      "2021-04-29 21:59:39 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 22:00:16 | INFO | hw5.seq2seq | example source: but if you look into the eye of consciousness , that single eye you can see , i'm looking down , but let me tell you how i felt at that point .\n",
      "2021-04-29 22:00:16 | INFO | hw5.seq2seq | example hypothesis: 但如果你從意識的角度看 , 你能看見的那隻眼睛 , 我在向下看 , 但讓我告訴你們我在那個時候的感受 。\n",
      "2021-04-29 22:00:16 | INFO | hw5.seq2seq | example reference: 但如果你看看意識的眼睛 , 你可以看到那單一隻眼睛 , 我在向下看 , 但讓我告訴你我當時的感受 。\n",
      "2021-04-29 22:00:16 | INFO | hw5.seq2seq | validation loss:\t2.9321\n",
      "2021-04-29 22:00:16 | INFO | hw5.seq2seq | BLEU = 29.37 59.9/36.0/22.9/15.3 (BP = 0.996 ratio = 0.996 hyp_len = 111315 ref_len = 111811)\n",
      "2021-04-29 22:00:17 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint29.pt\n",
      "2021-04-29 22:00:17 | INFO | hw5.seq2seq | end of epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 22:13:00 | INFO | hw5.seq2seq | training loss: 2.2607\n",
      "2021-04-29 22:13:00 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 22:13:37 | INFO | hw5.seq2seq | example source: in 1975 , he lost again .\n",
      "2021-04-29 22:13:37 | INFO | hw5.seq2seq | example hypothesis: 1975年 , 他再次失去\n",
      "2021-04-29 22:13:37 | INFO | hw5.seq2seq | example reference: 1975年 , 他又沒選上 。\n",
      "2021-04-29 22:13:37 | INFO | hw5.seq2seq | validation loss:\t2.9413\n",
      "2021-04-29 22:13:37 | INFO | hw5.seq2seq | BLEU = 28.98 60.2/36.0/22.8/15.2 (BP = 0.984 ratio = 0.984 hyp_len = 110070 ref_len = 111811)\n",
      "2021-04-29 22:13:38 | INFO | hw5.seq2seq | saved epoch checkpoint: /home/bill/Desktop/Graduate_course/ML2021/hw5/checkpoints/rnn-bt/checkpoint30.pt\n",
      "2021-04-29 22:13:38 | INFO | hw5.seq2seq | end of epoch 30\n"
     ]
    }
   ],
   "source": [
    "epoch_itr = load_data_iterator(task, \"train\", config.start_epoch, config.max_tokens, config.num_workers)\n",
    "try_load_checkpoint(model, optimizer, name=config.resume)\n",
    "print(epoch_itr.next_epoch_idx)\n",
    "while epoch_itr.next_epoch_idx <= config.max_epoch:\n",
    "    # train for one epoch\n",
    "    train_one_epoch(epoch_itr, model, task, criterion, optimizer, config.accum_steps)\n",
    "    stats = validate_and_save(model, task, criterion, optimizer, epoch=epoch_itr.epoch)\n",
    "    logger.info(\"end of epoch {}\".format(epoch_itr.epoch))    \n",
    "    epoch_itr = load_data_iterator(task, \"train\", epoch_itr.next_epoch_idx, config.max_tokens, config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(checkpoint_upper_bound=None, inputs=['./checkpoints/rnn-bt'], num_epoch_checkpoints=5, num_update_checkpoints=None, output='./checkpoints/rnn-bt/avg_last_5_checkpoint.pt')\n",
      "averaging checkpoints:  ['./checkpoints/rnn-bt/checkpoint30.pt', './checkpoints/rnn-bt/checkpoint29.pt', './checkpoints/rnn-bt/checkpoint28.pt', './checkpoints/rnn-bt/checkpoint27.pt', './checkpoints/rnn-bt/checkpoint26.pt']\n",
      "Finished writing averaged checkpoint to ./checkpoints/rnn-bt/avg_last_5_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "checkdir=config.savedir\n",
    "!python3 ./fairseq/scripts/average_checkpoints.py \\\n",
    "--inputs {checkdir} \\\n",
    "--num-epoch-checkpoints 5 \\\n",
    "--output {checkdir}/avg_last_5_checkpoint.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 22:17:59 | INFO | hw5.seq2seq | loaded checkpoint checkpoints/rnn-bt/avg_last_5_checkpoint.pt: step=unknown loss=2.9413042068481445 bleu=28.98349600027535\n",
      "2021-04-29 22:17:59 | INFO | hw5.seq2seq | begin validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 22:18:34 | INFO | hw5.seq2seq | example source: so i hope i've convinced you the brain is there and evolved to control movement .\n",
      "2021-04-29 22:18:34 | INFO | hw5.seq2seq | example hypothesis: 所以 , 我希望我已經說服各位大腦是在那裡演化來控制動作的 。\n",
      "2021-04-29 22:18:34 | INFO | hw5.seq2seq | example reference: 我希望我能讓你了解 , 大腦的存在就是為了控制動作的 。\n",
      "2021-04-29 22:18:34 | INFO | hw5.seq2seq | validation loss:\t2.9119\n",
      "2021-04-29 22:18:34 | INFO | hw5.seq2seq | BLEU = 29.60 60.7/36.6/23.4/15.7 (BP = 0.985 ratio = 0.985 hyp_len = 110187 ref_len = 111811)\n"
     ]
    }
   ],
   "source": [
    "try_load_checkpoint(model, name=\"avg_last_5_checkpoint.pt\")\n",
    "validate(model, task, criterion, log_to_wandb=False)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 22:19:43 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./DATA/data-bin/ted2020_with_mono/test.zh-en.en\n",
      "2021-04-29 22:19:43 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./DATA/data-bin/ted2020_with_mono/test.zh-en.zh\n",
      "2021-04-29 22:19:43 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020_with_mono test en-zh 4000 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prediction: 100%|██████████| 33/33 [00:30<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_prediction( model, task )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C1cCT6o6Lnv"
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMbY7tMb6Lnv"
   },
   "source": [
    "1. <a name=ott2019fairseq></a>Ott, M., Edunov, S., Baevski, A., Fan, A., Gross, S., Ng, N., ... & Auli, M. (2019, June). fairseq: A Fast, Extensible Toolkit for Sequence Modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations) (pp. 48-53).\n",
    "2. <a name=vaswani2017></a>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017, December). Attention is all you need. In Proceedings of the 31st International Conference on Neural Information Processing Systems (pp. 6000-6010).\n",
    "3. <a name=reimers-2020-multilingual-sentence-bert></a>Reimers, N., & Gurevych, I. (2020, November). Making Monolingual Sentence Embeddings Multilingual Using Knowledge Distillation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 4512-4525).\n",
    "4. <a name=tiedemann2012parallel></a>Tiedemann, J. (2012, May). Parallel Data, Tools and Interfaces in OPUS. In Lrec (Vol. 2012, pp. 2214-2218).\n",
    "5. <a name=kudo-richardson-2018-sentencepiece></a>Kudo, T., & Richardson, J. (2018, November). SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (pp. 66-71).\n",
    "6. <a name=sennrich-etal-2016-improving></a>Sennrich, R., Haddow, B., & Birch, A. (2016, August). Improving Neural Machine Translation Models with Monolingual Data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 86-96).\n",
    "7. <a name=edunov-etal-2018-understanding></a>Edunov, S., Ott, M., Auli, M., & Grangier, D. (2018). Understanding Back-Translation at Scale. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 489-500).\n",
    "8. https://github.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus\n",
    "9. https://ithelp.ithome.com.tw/articles/10233122\n",
    "10. https://nlp.seas.harvard.edu/2018/04/03/attention.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pikyK9mR6Lnw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "「HW05_ZH.ipynb」的副本",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
